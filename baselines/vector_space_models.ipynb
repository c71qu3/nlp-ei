{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb53c8c4",
   "metadata": {},
   "source": [
    "# Vector Space Models\n",
    "\n",
    "### Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b578fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/guaya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rank_bm25 import BM25Okapi\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_scorer\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from typing import Dict, List, Union, Any\n",
    "\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5006017",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92d077",
   "metadata": {},
   "source": [
    "Load processed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fa488f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2511.21678v1\n",
      "2511.21636v1\n",
      "2511.21591v1\n",
      "2511.21570v1\n",
      "2511.21569v1\n",
      "2511.21522v1\n",
      "2511.21471v1\n",
      "2511.21460v1\n",
      "2511.21444v1\n",
      "2511.21398v1\n"
     ]
    }
   ],
   "source": [
    "DIR_DATA = os.path.join(\"..\", \"data\")\n",
    "DIR_PROCESSED = os.path.join(DIR_DATA, \"processed\")\n",
    "\n",
    "\n",
    "papers = {}\n",
    "for filename in os.listdir(DIR_PROCESSED):\n",
    "    if filename.lower().endswith(\".json\"):\n",
    "\n",
    "        filepath = os.path.join(DIR_PROCESSED, filename)\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            papers[filename[:-5]] = {\"processed\": json.load(f)}\n",
    "\n",
    "for identifier in papers:\n",
    "    print(identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aadd9c3",
   "metadata": {},
   "source": [
    "Load abstracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc82a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_RAW = os.path.join(DIR_DATA, \"raw\", \"abstracts\")\n",
    "\n",
    "\n",
    "for identifier, paper in papers.items():\n",
    "    filepath = os.path.join(DIR_RAW, identifier + \".txt\")\n",
    "\n",
    "    with open(filepath,'r', encoding=\"utf-8\") as f:\n",
    "        paper[\"abstract\"] = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc969b",
   "metadata": {},
   "source": [
    "### Tokenize and Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cfb0718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_paper(text: str) -> Dict[str, Union[str, List[List[str]]]]:\n",
    "    \"\"\"Process text into plain and lemmatized sentences.\"\"\"\n",
    "    paper = {}\n",
    "\n",
    "    stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    sentence_split = nltk.sent_tokenize(text)\n",
    "    word_split = [\n",
    "        nltk.word_tokenize(sentence) for\n",
    "        sentence in sentence_split]\n",
    "\n",
    "    plain = []\n",
    "    lemma = []\n",
    "    for i, sentence in enumerate(word_split):\n",
    "        lemma.append([])\n",
    "        plain.append(sentence_split[i].replace('\\n', ''))\n",
    "\n",
    "        for word in sentence:\n",
    "            token = word.lower()\n",
    "            if token.isalpha() and token not in stop_words:\n",
    "                lemma[-1].append(lemmatizer.lemmatize(token))\n",
    "\n",
    "        # Discard sentences where\n",
    "        # lemmatization returns nothing\n",
    "        if not lemma[-1]:\n",
    "            lemma.pop()\n",
    "            plain.pop()\n",
    "\n",
    "    return {\"lemma\": lemma, \"plain\": plain }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458238ed",
   "metadata": {},
   "source": [
    "Pre-process the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "452abc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for identifier, data in papers.items():\n",
    "\n",
    "    paper = data[\"processed\"]\n",
    "    paragraphs = []\n",
    "    for section in paper:\n",
    "        paragraphs.append(section[\"paragraphs\"])\n",
    "\n",
    "    papers[identifier][\"sentences\"] = pre_process_paper(\"\\n\".join(paragraphs))\n",
    "    papers[identifier][\"abstract\"] = pre_process_paper(papers[identifier][\"abstract\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3477e2f3",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cbc202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_rank_sentences(lemmatized: str) -> List[int]:\n",
    "    \"\"\"Order index of sentences by TF-IDF similarity to whole document.\"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    sentences_list = [' '.join(s) for s in lemmatized]\n",
    "    sentences = vectorizer.fit_transform(sentences_list)\n",
    "    document = vectorizer.transform([' '.join(sentences_list)])\n",
    "    scores = cosine_similarity(document, sentences).flatten()\n",
    "\n",
    "    indexes = sorted(\n",
    "        range(len(scores)),\n",
    "        key=lambda i: scores[i],\n",
    "        reverse=True)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eef67ad",
   "metadata": {},
   "source": [
    "Calculate TF-IDF scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06bd7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "for identifier, data in papers.items():\n",
    "    sentences = data[\"sentences\"]\n",
    "\n",
    "    papers[identifier][\"rank\"] = {}\n",
    "    papers[identifier][\"rank\"][\"TF-IDF\"] = tfidf_rank_sentences(sentences[\"lemma\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a131559",
   "metadata": {},
   "source": [
    "Calculate similarity scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69ca5fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2511.21678v1 {'rouge1': 0.3203592814371257, 'rouge2': 0.08408408408408408, 'rougeL': 0.1467065868263473, 'bertscore_f1': 0.7764676213264465}\n",
      "2511.21636v1 {'rouge1': 0.3690036900369004, 'rouge2': 0.10408921933085502, 'rougeL': 0.1845018450184502, 'bertscore_f1': 0.7698068022727966}\n",
      "2511.21591v1 {'rouge1': 0.36363636363636365, 'rouge2': 0.10953346855983773, 'rougeL': 0.19797979797979795, 'bertscore_f1': 0.7866191267967224}\n",
      "2511.21570v1 {'rouge1': 0.4650205761316873, 'rouge2': 0.0950413223140496, 'rougeL': 0.2139917695473251, 'bertscore_f1': 0.8214453458786011}\n",
      "2511.21569v1 {'rouge1': 0.21052631578947367, 'rouge2': 0.03571428571428572, 'rougeL': 0.12280701754385966, 'bertscore_f1': 0.7886336445808411}\n",
      "2511.21522v1 {'rouge1': 0.4268292682926829, 'rouge2': 0.11020408163265306, 'rougeL': 0.19105691056910568, 'bertscore_f1': 0.8165643811225891}\n",
      "2511.21471v1 {'rouge1': 0.4157303370786517, 'rouge2': 0.12781954887218047, 'rougeL': 0.1797752808988764, 'bertscore_f1': 0.8021263480186462}\n",
      "2511.21460v1 {'rouge1': 0.2993006993006993, 'rouge2': 0.0673211781206171, 'rougeL': 0.11468531468531469, 'bertscore_f1': 0.6591107249259949}\n",
      "2511.21444v1 {'rouge1': 0.38256658595641646, 'rouge2': 0.10705596107055962, 'rougeL': 0.1694915254237288, 'bertscore_f1': 0.8142628073692322}\n",
      "2511.21398v1 {'rouge1': 0.36518046709129515, 'rouge2': 0.0767590618336887, 'rougeL': 0.15711252653927815, 'bertscore_f1': 0.7820037603378296}\n"
     ]
    }
   ],
   "source": [
    "def build_summary(\n",
    "        sentences: List[List[str]],\n",
    "        indexes: List[int]\n",
    "    ) -> str:\n",
    "    \"\"\"Build summary from TF-IDF or BM25 ranking.\"\"\"\n",
    "    return ' '.join([sentences[s] for s in indexes])\n",
    "\n",
    "\n",
    "def rouge_abstract_similarity(\n",
    "        summary_str: str,\n",
    "        abstract: List[str]\n",
    "    ) -> Dict[str, float]:\n",
    "    \"\"\"Calculate ROUGE similarities between summary and abstract.\"\"\"\n",
    "    abstract_str = ' '.join(abstract)\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    score = scorer.score(abstract_str, summary_str)\n",
    "    return {\n",
    "        \"rouge1\": score[\"rouge1\"].fmeasure,\n",
    "        \"rouge2\": score[\"rouge2\"].fmeasure,\n",
    "        \"rougeL\": score[\"rougeL\"].fmeasure}\n",
    "\n",
    "\n",
    "def bert_abstract_similarity(\n",
    "        summary_str,\n",
    "        abstract: List[str]\n",
    "    ) -> float:\n",
    "    \"\"\"Calculate BertScore similarity between summary and abstract.\"\"\"\n",
    "    abstract_str = ' '.join(abstract)\n",
    "\n",
    "    _, _, F1 = bert_scorer(\n",
    "        [summary_str],\n",
    "        [abstract_str],\n",
    "        lang=\"en\",\n",
    "        model_type=\"distilbert-base-uncased\")\n",
    "    return float(F1[0])\n",
    "\n",
    "\n",
    "for identifier, paper in papers.items():\n",
    "\n",
    "    paper[\"score\"] = {}\n",
    "    n = len(paper[\"abstract\"][\"plain\"])\n",
    "    summary = build_summary(\n",
    "        paper[\"sentences\"][\"plain\"],\n",
    "        paper[\"rank\"][\"TF-IDF\"][:n])\n",
    "\n",
    "    paper[\"score\"][\"TF-IDF\"] = rouge_abstract_similarity(\n",
    "        summary,\n",
    "        paper[\"abstract\"][\"plain\"])\n",
    "\n",
    "    paper[\"score\"][\"TF-IDF\"][\"bertscore_f1\"] = bert_abstract_similarity(\n",
    "        summary,\n",
    "        paper[\"abstract\"][\"plain\"])\n",
    "        \n",
    "    print(identifier, paper[\"score\"][\"TF-IDF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de38def",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "195d59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_rank_sentences(lemmatized: str) -> List[int]:\n",
    "    \"\"\"Order index of sentences by BM25 similarity to whole document.\"\"\"\n",
    "    sentences = BM25Okapi(lemmatized)\n",
    "    scores = sentences.get_scores(sum(lemmatized, []))\n",
    "\n",
    "    indexes = sorted(\n",
    "        range(len(scores)),\n",
    "        key=lambda i: scores[i],\n",
    "        reverse=True)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cfcaff",
   "metadata": {},
   "source": [
    "Calculate BM25 scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3839e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for identifier, data in papers.items():\n",
    "    sentences = data[\"sentences\"]\n",
    "\n",
    "    papers[identifier][\"rank\"][\"BM25\"] = bm25_rank_sentences(sentences[\"lemma\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22089fab",
   "metadata": {},
   "source": [
    "Calculate similarity scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c5a9298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2511.21678v1 {'rouge1': 0.14302741358760426, 'rouge2': 0.0047789725209080045, 'rougeL': 0.06436233611442194, 'bertscore_f1': 0.6160234212875366}\n",
      "2511.21636v1 {'rouge1': 0.144, 'rouge2': 0.004016064257028113, 'rougeL': 0.08399999999999999, 'bertscore_f1': 0.6361541152000427}\n",
      "2511.21591v1 {'rouge1': 0.38223938223938225, 'rouge2': 0.09302325581395349, 'rougeL': 0.17374517374517373, 'bertscore_f1': 0.7891222238540649}\n",
      "2511.21570v1 {'rouge1': 0.4787018255578094, 'rouge2': 0.10183299389002036, 'rougeL': 0.2150101419878296, 'bertscore_f1': 0.8201526999473572}\n",
      "2511.21569v1 {'rouge1': 0.19298245614035087, 'rouge2': 0.01785714285714286, 'rougeL': 0.15789473684210525, 'bertscore_f1': 0.7706606388092041}\n",
      "2511.21522v1 {'rouge1': 0.4294234592445328, 'rouge2': 0.11576846307385229, 'rougeL': 0.18687872763419483, 'bertscore_f1': 0.8104702830314636}\n",
      "2511.21471v1 {'rouge1': 0.4307116104868913, 'rouge2': 0.13157894736842102, 'rougeL': 0.17228464419475656, 'bertscore_f1': 0.8052541613578796}\n",
      "2511.21460v1 {'rouge1': 0.29101283880171186, 'rouge2': 0.07725321888412018, 'rougeL': 0.12268188302425106, 'bertscore_f1': 0.6591107249259949}\n",
      "2511.21444v1 {'rouge1': 0.34086242299794656, 'rouge2': 0.09072164948453608, 'rougeL': 0.13963039014373715, 'bertscore_f1': 0.7625104188919067}\n",
      "2511.21398v1 {'rouge1': 0.34458259325044405, 'rouge2': 0.0641711229946524, 'rougeL': 0.13854351687388985, 'bertscore_f1': 0.7711589336395264}\n"
     ]
    }
   ],
   "source": [
    "for identifier, paper in papers.items():\n",
    "\n",
    "    n = len(paper[\"abstract\"][\"plain\"])\n",
    "    summary = build_summary(\n",
    "        paper[\"sentences\"][\"plain\"],\n",
    "        paper[\"rank\"][\"BM25\"][:n])\n",
    "\n",
    "    paper[\"score\"][\"BM25\"] = rouge_abstract_similarity(\n",
    "        summary,\n",
    "        paper[\"abstract\"][\"plain\"])\n",
    "\n",
    "    paper[\"score\"][\"BM25\"][\"bertscore_f1\"] = bert_abstract_similarity(\n",
    "        summary,\n",
    "        paper[\"abstract\"][\"plain\"])\n",
    "        \n",
    "    print(identifier, paper[\"score\"][\"BM25\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab030c8",
   "metadata": {},
   "source": [
    "## Extra: Lead N & Lead N by Section\n",
    "\n",
    "Calculating the scores for the _Lead N_ and _Lead N by Section_ predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef523fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(DIR_DATA, \"lead_n_results.json\")\n",
    "with open(filepath, 'r', encoding='utf-8') as f:\n",
    "    lead_n_results = json.load(f)\n",
    "\n",
    "for identifier in papers:\n",
    "    papers[identifier][\"lead_n\"] = lead_n_results[identifier][\"lead_n\"]\n",
    "    papers[identifier][\"lead_n_by_section\"] = lead_n_results[identifier][\"lead_n_by_section\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac63d26",
   "metadata": {},
   "source": [
    "Calculate similarity scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3925e627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead N\n",
      "2511.21678v1 {'rouge1': 0.31216931216931215, 'rouge2': 0.05319148936170213, 'rougeL': 0.13756613756613756, 'bertscore_f1': 0.7616528272628784}\n",
      "2511.21636v1 {'rouge1': 0.35782747603833864, 'rouge2': 0.07717041800643087, 'rougeL': 0.17252396166134185, 'bertscore_f1': 0.788264274597168}\n",
      "2511.21591v1 {'rouge1': 0.3409836065573771, 'rouge2': 0.07260726072607261, 'rougeL': 0.15081967213114755, 'bertscore_f1': 0.7599596977233887}\n",
      "2511.21570v1 {'rouge1': 0.23300970873786403, 'rouge2': 0.032573289902280124, 'rougeL': 0.11650485436893201, 'bertscore_f1': 0.7540249228477478}\n",
      "2511.21569v1 {'rouge1': 0.3170731707317073, 'rouge2': 0.07407407407407408, 'rougeL': 0.15853658536585366, 'bertscore_f1': 0.8002178072929382}\n",
      "2511.21522v1 {'rouge1': 0.3095238095238095, 'rouge2': 0.023952095808383235, 'rougeL': 0.13095238095238096, 'bertscore_f1': 0.7477512955665588}\n",
      "2511.21471v1 {'rouge1': 0.26315789473684215, 'rouge2': 0.05291005291005291, 'rougeL': 0.11052631578947368, 'bertscore_f1': 0.7297408580780029}\n",
      "2511.21460v1 {'rouge1': 0.1987179487179487, 'rouge2': 0.03870967741935484, 'rougeL': 0.11538461538461539, 'bertscore_f1': 0.7562789916992188}\n",
      "2511.21444v1 {'rouge1': 0.3214285714285714, 'rouge2': 0.05755395683453238, 'rougeL': 0.16428571428571428, 'bertscore_f1': 0.7929290533065796}\n",
      "2511.21398v1 {'rouge1': 0.3006134969325153, 'rouge2': 0.061728395061728385, 'rougeL': 0.14110429447852763, 'bertscore_f1': 0.7609738111495972}\n",
      "Lead N by Section\n",
      "2511.21678v1 {'rouge1': 0.3665594855305467, 'rouge2': 0.08709677419354839, 'rougeL': 0.1672025723472669, 'bertscore_f1': 0.7891561388969421}\n",
      "2511.21636v1 {'rouge1': 0.2810590631364562, 'rouge2': 0.06952965235173823, 'rougeL': 0.1384928716904277, 'bertscore_f1': 0.7634981870651245}\n",
      "2511.21591v1 {'rouge1': 0.412639405204461, 'rouge2': 0.11940298507462688, 'rougeL': 0.2007434944237918, 'bertscore_f1': 0.788192868232727}\n",
      "2511.21570v1 {'rouge1': 0.41600000000000004, 'rouge2': 0.08042895442359249, 'rougeL': 0.20800000000000002, 'bertscore_f1': 0.8070022463798523}\n",
      "2511.21569v1 {'rouge1': 0.09575923392612859, 'rouge2': 0.019204389574759943, 'rougeL': 0.046511627906976744, 'bertscore_f1': 0.7397897839546204}\n",
      "2511.21522v1 {'rouge1': 0.38476953907815625, 'rouge2': 0.08853118712273644, 'rougeL': 0.1723446893787575, 'bertscore_f1': 0.7711299657821655}\n",
      "2511.21471v1 {'rouge1': 0.3940298507462686, 'rouge2': 0.10179640718562875, 'rougeL': 0.17014925373134326, 'bertscore_f1': 0.7941938638687134}\n",
      "2511.21460v1 {'rouge1': 0.2616984402079723, 'rouge2': 0.09375, 'rougeL': 0.10051993067590989, 'bertscore_f1': 0.8027015924453735}\n",
      "2511.21444v1 {'rouge1': 0.39499999999999996, 'rouge2': 0.12060301507537688, 'rougeL': 0.205, 'bertscore_f1': 0.8017568588256836}\n",
      "2511.21398v1 {'rouge1': 0.3365253077975376, 'rouge2': 0.10425240054869685, 'rougeL': 0.16415868673050615, 'bertscore_f1': 0.7878495454788208}\n"
     ]
    }
   ],
   "source": [
    "print(\"Lead N\")\n",
    "for identifier, paper in papers.items():\n",
    "\n",
    "    paper[\"score\"][\"lead_n\"] = rouge_abstract_similarity(\n",
    "        papers[identifier][\"lead_n\"],\n",
    "        paper[\"abstract\"][\"plain\"])\n",
    "\n",
    "    paper[\"score\"][\"lead_n\"][\"bertscore_f1\"] = bert_abstract_similarity(\n",
    "        papers[identifier][\"lead_n\"],\n",
    "        paper[\"abstract\"][\"plain\"])\n",
    "        \n",
    "    print(identifier, paper[\"score\"][\"lead_n\"])\n",
    "\n",
    "print(\"Lead N by Section\")\n",
    "for identifier, paper in papers.items():\n",
    "\n",
    "    paper[\"score\"][\"lead_n_by_section\"] = rouge_abstract_similarity(\n",
    "        papers[identifier][\"lead_n_by_section\"],\n",
    "        paper[\"abstract\"][\"plain\"])\n",
    "\n",
    "    paper[\"score\"][\"lead_n_by_section\"][\"bertscore_f1\"] = bert_abstract_similarity(\n",
    "        papers[identifier][\"lead_n_by_section\"],\n",
    "        paper[\"abstract\"][\"plain\"])\n",
    "        \n",
    "    print(identifier, paper[\"score\"][\"lead_n_by_section\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b1adfc",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30b83420",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(\"..\", \"data\", \"tfidf_bm25_lead_results.json\")\n",
    "\n",
    "with open(filepath, \"w\") as f:\n",
    "    json.dump(papers, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8a877",
   "metadata": {},
   "source": [
    "by [Manuel Velarde](mailto:manuel@velarde.me)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
