{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f3093a",
   "metadata": {},
   "source": [
    "# RAG Summarization with BM25 and LLMs\n",
    "\n",
    "### Implementation Description\n",
    "\n",
    "| Step | Description | Rationale | Comment |\n",
    "|------|-------------|-----------|---------|\n",
    "| Process source document | Break paper into sentences. Encode the full document together, and each sentence independently. Tokenize and lemmatize text. |  | Using `verbatim_rag` to read HTML files. |\n",
    "| Select relevant sentences | Calculate **BM25** similarity score between sentences and full document. Request an LLM model to extract the theme | This was the most reliable method for selecting sentences from the baseline results. |  |\n",
    "| Shape summary from sentences | Use **LLM** to shape selected sentences into summary. | Plain `rank_bm25` results are disjointed and out of order. |  |\n",
    "| Append supporting citation | Use `verbatim_rag` to identify supporting material in the original paper. |  |  |\n",
    "\n",
    "#### Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed50a055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mitre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mitre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Tuple, List\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import nltk\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from verbatim_rag.schema import DocumentSchema\n",
    "from verbatim_rag.chunker_providers import MarkdownChunkerProvider\n",
    "from verbatim_rag.embedding_providers import SentenceTransformersProvider\n",
    "from verbatim_rag.vector_stores import LocalMilvusStore\n",
    "from verbatim_rag import VerbatimIndex, VerbatimRAG\n",
    "from verbatim_rag.core import LLMClient\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "assert nltk.download('wordnet')\n",
    "assert nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "279a9d93-99c9-4a50-bc68-b8d7fa5325c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d092737-d763-405a-9e3c-0564c80eefee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52fbf9a",
   "metadata": {},
   "source": [
    "#### Constants\n",
    "\n",
    "Using `verbatim_rag` to load documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "474179e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARXIV_URL = \"https://arxiv.org/pdf/\"\n",
    "HTML_PATH = os.path.join(\"..\", \"data\", \"raw\", \"htmls\")\n",
    "\n",
    "documents = glob.glob(f\"{HTML_PATH}/*.txt\")\n",
    "documents\n",
    "\n",
    "DOCUMENT_ID = [\n",
    "    '2511.21398v1',\n",
    "    '2511.21444v1',\n",
    "    '2511.21460v1',\n",
    "    '2511.21471v1',\n",
    "    '2511.21522v1',\n",
    "    '2511.21569v1',\n",
    "    '2511.21570v1',\n",
    "    '2511.21591v1',\n",
    "    '2511.21636v1',\n",
    "    '2511.21678v1',\n",
    "]\n",
    "\n",
    "DOCUMENT_ID = documents[0:10]\n",
    "\n",
    "#DOCUMENT_ID = [\"..\\\\data\\\\raw\\\\htmls\\\\2510.25320v1.txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7eb15e",
   "metadata": {},
   "source": [
    "#### Helper Functions\n",
    "\n",
    "Method to extract abstract using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7b79473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstract_from_(paper: str) -> Optional[str]:\n",
    "    \"\"\"Get abstract from Markdown text.\"\"\"\n",
    "    match = re.search(r'## Abstract\\s*(.+?)(?=\\n##)', paper, re.DOTALL)\n",
    "    if match:\n",
    "        abstract = match.group(1).strip()\n",
    "        # abstract = re.sub(r\"^\\s*\\.\\s*\\n*\", \"\", abstract)\n",
    "        return abstract\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee831430",
   "metadata": {},
   "source": [
    "Method to display Markdown strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c980334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_markdown_(text: str) -> None:\n",
    "    \"\"\"Print Markdown string.\"\"\"\n",
    "    display(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "43a3443d-8267-4776-a8f0-3c42212aa29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_bucket_sections(full_text):\n",
    "    # 1. Define the 4 Buckets\n",
    "    buckets = {\n",
    "        \"intro\": [],\n",
    "        \"methods\": [],\n",
    "        \"results\": [],\n",
    "        \"conclusion\": []\n",
    "    }\n",
    "    \n",
    "    # 2. Regex to find Top-Level Headers (e.g., \"## I Introduction\" or \"2. Methodology\")\n",
    "    # Matches lines starting with numbering (I, 1, 1.) or Markdowns (##) followed by text\n",
    "    # We ignore ### (subsections) effectively treating them as body text\n",
    "    header_pattern = re.compile(r'^(?:##\\s+|[IVX\\d]+\\.?\\s+)(.*)', re.MULTILINE)\n",
    "    \n",
    "    # Split text by these headers\n",
    "    # 'split' returns [text_before_first_header, header1, content1, header2, content2...]\n",
    "    segments = header_pattern.split(full_text)\n",
    "    \n",
    "    # Iterate through pairs of (Header, Content)\n",
    "    # Skip segments[0] (text before first header)\n",
    "    for i in range(1, len(segments), 2):\n",
    "        header_title = segments[i].strip().lower()\n",
    "        content = segments[i+1].strip()\n",
    "        \n",
    "        # 3. Semantic Mapping Logic\n",
    "        if any(x in header_title for x in ['intro', 'background', 'related', 'motivation']):\n",
    "            buckets['intro'].append(content)\n",
    "            \n",
    "        elif any(x in header_title for x in ['method', 'formulation', 'system', 'approach', 'model', 'data', 'architecture']):\n",
    "            buckets['methods'].append(content)\n",
    "            \n",
    "        elif any(x in header_title for x in ['result', 'experiment', 'evaluation', 'perform', 'metric', 'ablation']):\n",
    "            buckets['results'].append(content)\n",
    "            \n",
    "        elif any(x in header_title for x in ['conclusion', 'discussion', 'future']):\n",
    "            buckets['conclusion'].append(content)\n",
    "            \n",
    "        elif 'reference' in header_title:\n",
    "            continue # Drop references\n",
    "            \n",
    "        else:\n",
    "            # Fallback: If we can't guess, put it in Methods (safest bet for middle sections)\n",
    "            # Or append to the previous bucket found\n",
    "            buckets['methods'].append(content)\n",
    "\n",
    "    # 4. Join the lists back into single text blocks\n",
    "    return {\n",
    "        \"intro_text\": \"\\n\".join(buckets['intro']),\n",
    "        \"methods_text\": \"\\n\".join(buckets['methods']),\n",
    "        \"results_text\": \"\\n\".join(buckets['results']),\n",
    "        \"conclusion_text\": \"\\n\".join(buckets['conclusion'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf5e2c",
   "metadata": {},
   "source": [
    "## Process Source Documents\n",
    "\n",
    "The `verbatim_rag` library captures the abstract correctly in all examples, unlike the processed used for the baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "181993e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 19:49:23,844 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2026-01-12 19:49:23,961 - INFO - Going to convert document batch...\n",
      "2026-01-12 19:49:23,962 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2026-01-12 19:49:23,962 - INFO - Processing document 2510.24832v1.txt\n",
      "2026-01-12 19:49:24,168 - INFO - Finished converting document 2510.24832v1.txt in 0.33 sec.\n",
      "2026-01-12 19:49:24,271 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2026-01-12 19:49:24,913 - INFO - Going to convert document batch...\n",
      "2026-01-12 19:49:24,914 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2026-01-12 19:49:24,915 - INFO - Processing document 2510.25005v1.txt\n",
      "2026-01-12 19:49:25,452 - INFO - Finished converting document 2510.25005v1.txt in 1.18 sec.\n",
      "2026-01-12 19:49:25,604 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2026-01-12 19:49:25,789 - INFO - Going to convert document batch...\n",
      "2026-01-12 19:49:25,790 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2026-01-12 19:49:25,790 - INFO - Processing document 2510.25007v1.txt\n",
      "2026-01-12 19:49:25,954 - INFO - Finished converting document 2510.25007v1.txt in 0.36 sec.\n",
      "2026-01-12 19:49:26,042 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2026-01-12 19:49:26,408 - INFO - Going to convert document batch...\n",
      "2026-01-12 19:49:26,409 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2026-01-12 19:49:26,410 - INFO - Processing document 2510.25014v1.txt\n",
      "2026-01-12 19:49:26,636 - INFO - Finished converting document 2510.25014v1.txt in 0.60 sec.\n",
      "2026-01-12 19:49:26,735 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2026-01-12 19:49:26,786 - INFO - Going to convert document batch...\n",
      "2026-01-12 19:49:26,787 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2026-01-12 19:49:26,788 - INFO - Processing document 2510.25065v1.txt\n",
      "2026-01-12 19:49:26,865 - INFO - Finished converting document 2510.25065v1.txt in 0.14 sec.\n",
      "2026-01-12 19:49:26,920 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2026-01-12 19:49:27,160 - INFO - Going to convert document batch...\n",
      "2026-01-12 19:49:27,161 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2026-01-12 19:49:27,162 - INFO - Processing document 2510.25091v1.txt\n",
      "2026-01-12 19:49:27,538 - INFO - Finished converting document 2510.25091v1.txt in 0.62 sec.\n",
      "2026-01-12 19:49:27,677 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2026-01-12 19:49:28,257 - INFO - Going to convert document batch...\n",
      "2026-01-12 19:49:28,257 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2026-01-12 19:49:28,258 - INFO - Processing document 2510.25101v1.txt\n",
      "2026-01-12 19:49:28,491 - INFO - Finished converting document 2510.25101v1.txt in 0.82 sec.\n",
      "2026-01-12 19:49:28,604 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2026-01-12 19:49:28,686 - INFO - Going to convert document batch...\n",
      "2026-01-12 19:49:28,687 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2026-01-12 19:49:28,688 - INFO - Processing document 2510.25179v1.txt\n",
      "2026-01-12 19:49:28,766 - INFO - Finished converting document 2510.25179v1.txt in 0.17 sec.\n",
      "2026-01-12 19:49:28,824 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2026-01-12 19:49:29,001 - INFO - Going to convert document batch...\n",
      "2026-01-12 19:49:29,002 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2026-01-12 19:49:29,003 - INFO - Processing document 2510.25205v1.txt\n",
      "2026-01-12 19:49:29,293 - INFO - Finished converting document 2510.25205v1.txt in 0.48 sec.\n",
      "2026-01-12 19:49:29,432 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2026-01-12 19:49:29,532 - INFO - Going to convert document batch...\n",
      "2026-01-12 19:49:29,532 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2026-01-12 19:49:29,533 - INFO - Processing document 2510.25223v1.txt\n",
      "2026-01-12 19:49:29,708 - INFO - Finished converting document 2510.25223v1.txt in 0.28 sec.\n"
     ]
    }
   ],
   "source": [
    "documents = {}\n",
    "papers = {}\n",
    "abstracts = {}\n",
    "document_sections = {}\n",
    "\n",
    "for document_id in DOCUMENT_ID:\n",
    "    # paper = DocumentSchema.from_url(url=ARXIV_URL + document_id)\n",
    "    #document = DocumentSchema.from_url(url=os.path.join(HTML_PATH, document_id + '.txt'))\n",
    "    document = DocumentSchema.from_url(url=document_id)\n",
    "    documents[document_id] = document\n",
    "    papers[document_id] = document.content\n",
    "    abstracts[document_id] = abstract_from_(document.content)\n",
    "    document_sections[document_id] = parse_and_bucket_sections(document.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e9441-a68e-4e56-9393-b221ba8b5b4d",
   "metadata": {},
   "source": [
    "## Obtain section summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "98f2d461-f359-43e6-882e-25baecdc95b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_section_summary(client: OpenAI, prompt_template: str, sentences: str) -> str:\n",
    "    response = client.responses.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        instructions=\"Only reply with a summarized paragraph.\",\n",
    "        input=prompt_template.format(sentences=sentences)\n",
    "    )\n",
    "    \n",
    "    return response.output_text\n",
    "\n",
    "def build_summary(client: OpenAI, summary_wordcount: int, prompt_template: str, intro_text: str, methods_text: str, results_text: str, conclusion_text: str) -> str:\n",
    "    response = client.responses.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        instructions=\"\"\"\n",
    "- Start directly with the problem or the proposed solution (do not say 'This paper presents...').\n",
    "- Connect the Methodology and Results logically using transition words (e.g., 'Consequently,' 'Specifically,' 'We observe that').\n",
    "- Ensure the tone is objective, impersonal, and authoritative.\n",
    "- Ensure the final word at least 200 relevant words long.\n",
    "- Do not use bullet points. Write a single paragraph.\"\"\",\n",
    "        input=prompt_template.format(summary_wordcount=summary_wordcount, \n",
    "                                     intro_text=intro_text, \n",
    "                                     methods_text=methods_text, \n",
    "                                     results_text=results_text, \n",
    "                                     conclusion_text=conclusion_text)\n",
    "    )\n",
    "    \n",
    "    return response.output_text\n",
    "\n",
    "def build_refiner(client: OpenAI, prompt_template: str, v1_summary: str):\n",
    "    response = client.responses.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        instructions=\"\"\"\n",
    "    Refinement Rules:\n",
    "    - Remove generic phrases like 'comprehensive experiments show that' or 'in order to'.\n",
    "    - Merge short sentences where possible to improve flow.\n",
    "    - Ensure the final word count is between 150-250 words.\n",
    "    - Crucial: Ensure the primary metric (the number/result) appears in the final text.\"\"\",\n",
    "        input=prompt_template.format(v1_summary=v1_summary)\n",
    "    )\n",
    "    \n",
    "    return response.output_text\n",
    "\n",
    "def build_exam_questions(client: OpenAI, prompt_template: str, full_text: str):\n",
    "    response = client.responses.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        input=prompt_template.format(full_text=full_text)\n",
    "    )\n",
    "    return response.output_text\n",
    "    \n",
    "def build_exam_answers(client: OpenAI, prompt_template: str, summary_text: str, questions: str):\n",
    "    response = client.responses.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        input=prompt_template.format(summary_text=summary_text,\n",
    "                                     questions=questions\n",
    "                                    )\n",
    "    )\n",
    "    return response.output_text\n",
    "\n",
    "def build_evaluation(client: OpenAI, prompt_template: str, question: str, ground_truth: str, answer: str):\n",
    "    response = client.responses.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        input=prompt_template.format(question=question,\n",
    "                                     ground_truth=ground_truth, \n",
    "                                     answer=answer)\n",
    "    )\n",
    "    return response.output_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ad1f21f5-9d51-4660-9c11-8b5b54c4c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTRO_PROMPT = \"\"\"\n",
    "Analyze the provided Introduction. Identify the following two elements clearly:\n",
    "- The Problem Space: What specific limitation, inefficiency, or challenge in the current state of the art is this paper addressing?\n",
    "- The Proposed Solution: What is the core system, framework, or hypothesis introduced to solve this?\n",
    "\n",
    "Introduction:\n",
    "{sentences}\n",
    "\"\"\"\n",
    "\n",
    "METHODS_PROMPT = \"\"\"\n",
    "Analyze the provided Methods/Methodology. Extract the technical specifics using the following keys:\n",
    "- Data/Environment: What specific datasets or source materials were used? (Do not invent any if they are not mentioned).\n",
    "- The Architecture: Briefly describe the model structure, algorithm, or experimental design.\n",
    "- Settings: Mention any critical hyperparameters, baselines, or comparisons used.\n",
    "\n",
    "Methods:\n",
    "{sentences}\n",
    "\"\"\"\n",
    "\n",
    "RESULTS_PROMPT = \"\"\"\n",
    "Analyze the provided Results. Extract the key evidence that supports the contribution:\n",
    "- Quantitative Metrics: Extract the specific main performance numbers strictly as they appear in the text. If more than 2 different metrics and numbers exist, only mention the two most important metrics.\n",
    "- Comparison: How did it perform relative to the baseline?\n",
    "- CONSTRAINT: Only extract numbers explicitly written in the text. If no specific quantitative metrics are provided, describe the qualitative improvement (e.g., \"significantly faster,\" \"more robust\") without inventing data. The numbers themselves must be an important part of the results.\n",
    "\n",
    "Results:\n",
    "{sentences}\n",
    "\"\"\"\n",
    "\n",
    "CONCLUSION_PROMPT = \"\"\"\n",
    "Analyze the provided Discussion/Conclusion. Summarize:\n",
    "- Interpretation: Why do the results matter?\n",
    "- Limitations: What is one key weakness acknowledged by the authors?\n",
    "- Impact: What is the final takeaway for the field?\n",
    "\n",
    "Conclusion:\n",
    "{sentences}\n",
    "\"\"\"\n",
    "\n",
    "JOINER_PROMPT = \"\"\"\n",
    "You are an expert technical writer. I will provide you with the key component parts of a research paper. Your goal is to weave them into a single, fluid abstract (approx. {summary_wordcount} words).\n",
    "Avoid including formulas.\n",
    "\n",
    "Instructions:\n",
    "1. Tone: Maintain an objective, scholarly tone suitable for the specific domain of the input (e.g., if the content is Computer Science, use CS terminology; if Biology, use Bio terminology).\n",
    "2. Accuracy: Do not introduce new information or numbers that are not present in the Input Data.\n",
    "3. Flow: Ensure smooth logical transitions between the Problem, Method, and Results.\n",
    "\n",
    "Input Data:\n",
    "- Context: {intro_text}\n",
    "- Methodology: {methods_text}\n",
    "- Key Findings: {results_text}\n",
    "- Implications: {conclusion_text}\n",
    "\"\"\"\n",
    "\n",
    "REFINER_PROMPT = \"\"\"\n",
    "Review the draft abstract below.\n",
    "Rewrite it to be denser and more concise, mimicking the style of a high-impact publication in this specific field.\n",
    "\n",
    "Constraints:\n",
    "- Retain all specific metrics and proper nouns (e.g., model names, dataset names).\n",
    "- Do not add sensationalist adjectives (e.g., avoid \"groundbreaking\" unless supported by data).\n",
    "- Focus on information density: reduce fluff words to allow more space for technical details.\n",
    "\n",
    "Draft: {v1_summary}\n",
    "\"\"\"\n",
    "\n",
    "OPENAI_MODEL = 'o4-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "577a4d96-9937-4921-a771-32fb7a6d9d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "key = os.getenv(\"OPENAI_API_KEY\")\n",
    "assert key\n",
    "\n",
    "client = OpenAI(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "5f1c8f8b-ec87-48b0-bdd0-14a7a73fa470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing document: ..\\data\\raw\\htmls\\2510.24832v1.txt\n",
      "Summarizing Introduction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:15:23,403 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Methods...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:15:33,853 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:15:40,155 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Conclusion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:15:47,214 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formulating cohesive summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:16:09,100 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refining summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:16:20,799 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:16:20,802 - INFO - Using default tokenizer.\n",
      "2026-01-12 23:16:20,820 - INFO - Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing document: ..\\data\\raw\\htmls\\2510.25005v1.txt\n",
      "Summarizing Introduction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:16:28,151 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Methods...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:16:39,003 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:16:43,289 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Conclusion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:16:47,780 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formulating cohesive summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:17:08,249 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refining summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:17:42,342 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:17:42,344 - INFO - Using default tokenizer.\n",
      "2026-01-12 23:17:42,351 - INFO - Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing document: ..\\data\\raw\\htmls\\2510.25007v1.txt\n",
      "Summarizing Introduction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:17:48,134 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Methods...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:17:58,752 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:18:04,664 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Conclusion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:18:08,564 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formulating cohesive summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:18:19,656 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refining summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:18:40,667 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:18:40,669 - INFO - Using default tokenizer.\n",
      "2026-01-12 23:18:40,691 - INFO - Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing document: ..\\data\\raw\\htmls\\2510.25014v1.txt\n",
      "Summarizing Introduction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:18:47,788 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Methods...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:18:57,120 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:19:04,605 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Conclusion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:19:08,196 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formulating cohesive summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:19:16,525 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refining summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:19:37,493 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:19:37,495 - INFO - Using default tokenizer.\n",
      "2026-01-12 23:19:37,519 - INFO - Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing document: ..\\data\\raw\\htmls\\2510.25065v1.txt\n",
      "Summarizing Introduction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:19:43,497 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Methods...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:19:52,112 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:19:58,123 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Conclusion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:20:03,348 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formulating cohesive summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:20:23,305 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refining summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:20:37,566 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:20:37,569 - INFO - Using default tokenizer.\n",
      "2026-01-12 23:20:37,584 - INFO - Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing document: ..\\data\\raw\\htmls\\2510.25091v1.txt\n",
      "Summarizing Introduction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:20:45,141 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Methods...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:21:04,068 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:21:13,417 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Conclusion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:21:20,882 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formulating cohesive summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:21:28,523 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refining summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:22:01,867 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:22:01,870 - INFO - Using default tokenizer.\n",
      "2026-01-12 23:22:01,889 - INFO - Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing document: ..\\data\\raw\\htmls\\2510.25101v1.txt\n",
      "Summarizing Introduction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:22:08,999 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Methods...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:22:16,069 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:22:30,829 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Conclusion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:22:35,404 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formulating cohesive summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:22:56,567 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refining summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:23:23,199 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:23:23,201 - INFO - Using default tokenizer.\n",
      "2026-01-12 23:23:23,222 - INFO - Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing document: ..\\data\\raw\\htmls\\2510.25179v1.txt\n",
      "Summarizing Introduction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:23:31,588 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Methods...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:23:38,613 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:23:46,517 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Conclusion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:23:51,353 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formulating cohesive summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:24:03,071 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refining summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:24:10,207 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:24:10,210 - INFO - Using default tokenizer.\n",
      "2026-01-12 23:24:10,226 - INFO - Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing document: ..\\data\\raw\\htmls\\2510.25205v1.txt\n",
      "Summarizing Introduction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:24:21,631 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Methods...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:24:33,355 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:24:39,661 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Conclusion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:24:51,793 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formulating cohesive summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:25:10,138 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refining summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:25:28,682 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:25:28,685 - INFO - Using default tokenizer.\n",
      "2026-01-12 23:25:28,721 - INFO - Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing document: ..\\data\\raw\\htmls\\2510.25223v1.txt\n",
      "Summarizing Introduction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:25:36,035 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Methods...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:25:46,097 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:25:54,432 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Conclusion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:25:57,918 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formulating cohesive summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:26:06,220 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refining summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:26:26,389 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:26:26,392 - INFO - Using default tokenizer.\n",
      "2026-01-12 23:26:26,414 - INFO - Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>method</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>bert_score_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.24832v1.txt</td>\n",
       "      <td>V1_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.629264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.24832v1.txt</td>\n",
       "      <td>REFINED_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.458128</td>\n",
       "      <td>0.216749</td>\n",
       "      <td>0.624795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25005v1.txt</td>\n",
       "      <td>V1_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.260274</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>0.583295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25005v1.txt</td>\n",
       "      <td>REFINED_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.199134</td>\n",
       "      <td>0.588976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25007v1.txt</td>\n",
       "      <td>V1_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.262425</td>\n",
       "      <td>0.147117</td>\n",
       "      <td>0.552201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25007v1.txt</td>\n",
       "      <td>REFINED_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.274882</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.549716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25014v1.txt</td>\n",
       "      <td>V1_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.200617</td>\n",
       "      <td>0.641713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25014v1.txt</td>\n",
       "      <td>REFINED_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.434004</td>\n",
       "      <td>0.241611</td>\n",
       "      <td>0.649669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25065v1.txt</td>\n",
       "      <td>V1_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.607236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25065v1.txt</td>\n",
       "      <td>REFINED_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.429752</td>\n",
       "      <td>0.214876</td>\n",
       "      <td>0.611708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25091v1.txt</td>\n",
       "      <td>V1_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.505338</td>\n",
       "      <td>0.199288</td>\n",
       "      <td>0.621106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25091v1.txt</td>\n",
       "      <td>REFINED_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25101v1.txt</td>\n",
       "      <td>V1_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.479279</td>\n",
       "      <td>0.176577</td>\n",
       "      <td>0.647105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25101v1.txt</td>\n",
       "      <td>REFINED_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.195455</td>\n",
       "      <td>0.645824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25179v1.txt</td>\n",
       "      <td>V1_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.402542</td>\n",
       "      <td>0.161017</td>\n",
       "      <td>0.624806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25179v1.txt</td>\n",
       "      <td>REFINED_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.414169</td>\n",
       "      <td>0.185286</td>\n",
       "      <td>0.646864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25205v1.txt</td>\n",
       "      <td>V1_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.464441</td>\n",
       "      <td>0.174165</td>\n",
       "      <td>0.619477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25205v1.txt</td>\n",
       "      <td>REFINED_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.365942</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.588055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25223v1.txt</td>\n",
       "      <td>V1_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.521583</td>\n",
       "      <td>0.230216</td>\n",
       "      <td>0.646867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>..\\data\\raw\\htmls\\2510.25223v1.txt</td>\n",
       "      <td>REFINED_SCAFFOLDED_TEMPLATING</td>\n",
       "      <td>0.463252</td>\n",
       "      <td>0.200445</td>\n",
       "      <td>0.633209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              paper_id                         method  \\\n",
       "0   ..\\data\\raw\\htmls\\2510.24832v1.txt       V1_SCAFFOLDED_TEMPLATING   \n",
       "1   ..\\data\\raw\\htmls\\2510.24832v1.txt  REFINED_SCAFFOLDED_TEMPLATING   \n",
       "2   ..\\data\\raw\\htmls\\2510.25005v1.txt       V1_SCAFFOLDED_TEMPLATING   \n",
       "3   ..\\data\\raw\\htmls\\2510.25005v1.txt  REFINED_SCAFFOLDED_TEMPLATING   \n",
       "4   ..\\data\\raw\\htmls\\2510.25007v1.txt       V1_SCAFFOLDED_TEMPLATING   \n",
       "5   ..\\data\\raw\\htmls\\2510.25007v1.txt  REFINED_SCAFFOLDED_TEMPLATING   \n",
       "6   ..\\data\\raw\\htmls\\2510.25014v1.txt       V1_SCAFFOLDED_TEMPLATING   \n",
       "7   ..\\data\\raw\\htmls\\2510.25014v1.txt  REFINED_SCAFFOLDED_TEMPLATING   \n",
       "8   ..\\data\\raw\\htmls\\2510.25065v1.txt       V1_SCAFFOLDED_TEMPLATING   \n",
       "9   ..\\data\\raw\\htmls\\2510.25065v1.txt  REFINED_SCAFFOLDED_TEMPLATING   \n",
       "10  ..\\data\\raw\\htmls\\2510.25091v1.txt       V1_SCAFFOLDED_TEMPLATING   \n",
       "11  ..\\data\\raw\\htmls\\2510.25091v1.txt  REFINED_SCAFFOLDED_TEMPLATING   \n",
       "12  ..\\data\\raw\\htmls\\2510.25101v1.txt       V1_SCAFFOLDED_TEMPLATING   \n",
       "13  ..\\data\\raw\\htmls\\2510.25101v1.txt  REFINED_SCAFFOLDED_TEMPLATING   \n",
       "14  ..\\data\\raw\\htmls\\2510.25179v1.txt       V1_SCAFFOLDED_TEMPLATING   \n",
       "15  ..\\data\\raw\\htmls\\2510.25179v1.txt  REFINED_SCAFFOLDED_TEMPLATING   \n",
       "16  ..\\data\\raw\\htmls\\2510.25205v1.txt       V1_SCAFFOLDED_TEMPLATING   \n",
       "17  ..\\data\\raw\\htmls\\2510.25205v1.txt  REFINED_SCAFFOLDED_TEMPLATING   \n",
       "18  ..\\data\\raw\\htmls\\2510.25223v1.txt       V1_SCAFFOLDED_TEMPLATING   \n",
       "19  ..\\data\\raw\\htmls\\2510.25223v1.txt  REFINED_SCAFFOLDED_TEMPLATING   \n",
       "\n",
       "      rouge1    rougeL  bert_score_f1  \n",
       "0   0.480000  0.224000       0.629264  \n",
       "1   0.458128  0.216749       0.624795  \n",
       "2   0.260274  0.164384       0.583295  \n",
       "3   0.303030  0.199134       0.588976  \n",
       "4   0.262425  0.147117       0.552201  \n",
       "5   0.274882  0.146919       0.549716  \n",
       "6   0.416667  0.200617       0.641713  \n",
       "7   0.434004  0.241611       0.649669  \n",
       "8   0.375000  0.185185       0.607236  \n",
       "9   0.429752  0.214876       0.611708  \n",
       "10  0.505338  0.199288       0.621106  \n",
       "11  0.448980  0.171429       0.617188  \n",
       "12  0.479279  0.176577       0.647105  \n",
       "13  0.436364  0.195455       0.645824  \n",
       "14  0.402542  0.161017       0.624806  \n",
       "15  0.414169  0.185286       0.646864  \n",
       "16  0.464441  0.174165       0.619477  \n",
       "17  0.365942  0.173913       0.588055  \n",
       "18  0.521583  0.230216       0.646867  \n",
       "19  0.463252  0.200445       0.633209  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_summaries_vs_abstract = {}\n",
    "scoring_results = []\n",
    "\n",
    "docs = document_sections.items()\n",
    "#docs = [list(document_sections.items())[-1]]\n",
    "\n",
    "for k, v in docs:\n",
    "    print(f\"Summarizing document: {k}\")\n",
    "    doc_content = document_sections[k]\n",
    "\n",
    "    print(f\"Summarizing Introduction...\")\n",
    "    intro_summary = build_summary_(client=client, \n",
    "                                   prompt_template=INTRO_PROMPT, \n",
    "                                   sentences=doc_content[\"intro_text\"])\n",
    "    print(f\"Summarizing Methods...\")\n",
    "    methods_summary = build_summary_(client=client, \n",
    "                                     prompt_template=METHODS_PROMPT, \n",
    "                                     sentences=doc_content[\"methods_text\"])\n",
    "    print(f\"Summarizing Results...\")\n",
    "    results_summary = build_summary_(client=client, \n",
    "                                     prompt_template=RESULTS_PROMPT, \n",
    "                                     sentences=doc_content[\"results_text\"])\n",
    "    print(f\"Summarizing Conclusion...\")\n",
    "    conclusion_summary = build_summary_(client=client, \n",
    "                                        prompt_template=CONCLUSION_PROMPT, \n",
    "                                        sentences=doc_content[\"conclusion_text\"])\n",
    "\n",
    "    print(f\"Formulating cohesive summary...\")\n",
    "    v1_summary = build_summary(client=client, \n",
    "                               summary_wordcount=200,\n",
    "                               prompt_template=JOINER_PROMPT, \n",
    "                               intro_text=intro_summary,\n",
    "                               methods_text=methods_summary, \n",
    "                               results_text=results_summary, \n",
    "                               conclusion_text=conclusion_summary\n",
    "                              )\n",
    "\n",
    "    print(f\"Refining summary...\")\n",
    "    refined_summary = build_refiner(client=client, \n",
    "                                    prompt_template=REFINER_PROMPT, \n",
    "                                    v1_summary=v1_summary)\n",
    "\n",
    "    curr_abstract = abstracts[k]\n",
    "    rag_summaries_vs_abstract[k] = {\"abstract\": curr_abstract, \n",
    "                                    \"v1_summary\": v1_summary,\n",
    "                                   \"refined_summary\": refined_summary}\n",
    "\n",
    "    \n",
    "    rouge_scores_subsection_llm_v1 = calculate_rouge_score(curr_abstract, \n",
    "                                                           v1_summary)\n",
    "    rouge_scores_subsection_llm_refined = calculate_rouge_score(curr_abstract, \n",
    "                                                                refined_summary)\n",
    "    \n",
    "    bert_scores_subsection_llm_v1 = calculate_bert_score(curr_abstract, \n",
    "                                                         v1_summary)\n",
    "    bert_scores_subsection_llm_refined = calculate_bert_score(curr_abstract, \n",
    "                                                              refined_summary)\n",
    "\n",
    "    scoring_results.append(\n",
    "        {\n",
    "            \"paper_id\": k, \n",
    "            \"method\": \"V1_SCAFFOLDED_TEMPLATING\",\n",
    "            \"rouge1\": rouge_scores_subsection_llm_v1[\"rouge1_fmeasure\"], \n",
    "            \"rougeL\": rouge_scores_subsection_llm_v1[\"rougeL_fmeasure\"],\n",
    "            \"bert_score_f1\": bert_scores_subsection_llm_v1[\"bertscore_f1\"]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    scoring_results.append(\n",
    "            {\n",
    "                \"paper_id\": k, \n",
    "                \"method\": \"REFINED_SCAFFOLDED_TEMPLATING\",\n",
    "                \"rouge1\": rouge_scores_subsection_llm_refined[\"rouge1_fmeasure\"], \n",
    "                \"rougeL\": rouge_scores_subsection_llm_refined[\"rougeL_fmeasure\"],\n",
    "                \"bert_score_f1\": bert_scores_subsection_llm_refined[\"bertscore_f1\"]\n",
    "            }\n",
    "        )\n",
    "\n",
    "df_results = pd.DataFrame(scoring_results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "581be2e8-597c-455e-9b04-22504585ea3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1341, 1961, 1293),\n",
       " (453, 1659, 1199),\n",
       " (1356, 2078, 1439),\n",
       " (1380, 3069, 1623),\n",
       " (1116, 1934, 1469),\n",
       " (2025, 2054, 1496),\n",
       " (1601, 2245, 1442),\n",
       " (1294, 2149, 1382),\n",
       " (2025, 2741, 1672),\n",
       " (1809, 2311, 1522)]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(len(d[\"abstract\"]), len(d[\"v1_summary\"]), len(d[\"refined_summary\"])) for d in rag_summaries_vs_abstract.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab70717",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2a690c8e-bd3e-47f3-89be-c1c30df2309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./summary_templating.json\", \"w\") as f:\n",
    "    json.dump(rag_summaries_vs_abstract, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f39ca2cc-1c01-4de5-acb8-769a23eb2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMINER_PROMPT = \"\"\"\n",
    "You are an expert researcher. Read the following Full Paper text.\n",
    "Generate 5 fact based questions that must be simple enough to be answered from a theoretical scientific abstract for this paper. Keep the answers limited to a single sentence if possible. \n",
    "You must ignore the paper's Abstract section and instead only rely on the rest of the paper. Choose your own questions to be answered that you consider would create a high quality scientific abstract based on the Introduction, Methodology, Results and Conclusions.\n",
    "For each question, provide the exact Ground Truth Answer from the text.\n",
    "\n",
    "Constraints:\n",
    "1. Question 1 must be about the **specific problem** addressed.\n",
    "2. Question 2 must be about the **methodology** used.\n",
    "3. Question 3 must be about the **quantitative results** (metrics, numbers).\n",
    "4. Question 4 must be about the **dataset or environment**.\n",
    "5. Question 5 must be about the **limitations or future work**.\n",
    "\n",
    "Format output as python compatible JSON list (in text format) with a question property and an answer property for each of the questions.\n",
    "\n",
    "Full Paper Text: {full_text}\n",
    "\"\"\"\n",
    "\n",
    "STUDENT_PROMPT = \"\"\"\n",
    "You are a student taking a test.\n",
    "Read the following Summary and answer the Questions based *strictly* on the information provided in that summary.\n",
    "If the information is not in the summary, answer \"NOT MENTIONED\".\n",
    "\n",
    "Summary: {summary_text}\n",
    "\n",
    "Questions:\n",
    "{questions}\n",
    "\n",
    "Format the output as a python list of answers.\n",
    "\"\"\"\n",
    "\n",
    "GRADER_PROMPT = \"\"\"\n",
    "Compare the Student's Answer to the Ground Truth Answer.\n",
    "Score 1 if the Student's Answer is correct and sufficiently semantically similar to the Ground Truth (typos and incomplete answers are OK, but complete fabrications are not acceptable).\n",
    "Score 0 if the Student's Answer is incorrect, vague, or \"NOT MENTIONED\".\n",
    "\n",
    "Q: {question}\n",
    "Ground Truth: {ground_truth}\n",
    "Student Answer: {answer}\n",
    "\n",
    "Return ONLY the score (0 or 1).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "dafbbd2f-64b7-4e6b-ae76-fb8bb538ff2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### ..\\data\\raw\\htmls\\2510.24832v1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:35:36,361 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:36:02,440 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:36:14,849 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:36:23,453 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question: What specific problem in RLVR data scheduling for LLM mathematical reasoning does this paper address?\n",
      "Ground truth: Existing RLVR data scheduling methods estimate query difficulty primarily via final solution accuracy and overlook richer query-level characteristics such as the structural complexity of the reasoning tree.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:36:25,158 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: Existing RLVR data-scheduling methods rely on final solution accuracy as a proxy for problem difficulty and overlook the structural complexity of a querys reasoning tree, leading to misprioritization of examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:36:27,245 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: Existing RLVR data scheduling methods estimate query difficulty via final solution accuracy, ignoring reasoningtree structure and misprioritizing samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:36:29,220 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: Existing RLVR data scheduling methods rely on path-based metrics to rank queries and overlook the structural complexity of their reasoning trees.\n",
      "\n",
      "\n",
      "Question: What methodology do the authors propose to better quantify and schedule queries during RLVR training?\n",
      "Ground truth: They introduce the Reasoning Score (r-score), a tree-based metric quantifying a query's learning potential under a fixed node-editing budget, and propose Re-Schedule, a data scheduling algorithm that dynamically weights queries from structurally simple to complex based on the r-score.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:36:32,616 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: They introduce the Reasoning Score (r-score), which measures a querys maximum accuracy gain under a fixed node-editing budget, and present the Re-Schedule algorithm to build approximate reasoning trees offline, simulate edits to compute r-scores, and dynamically weight samples in an easy-to-hard curriculum.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:36:35,682 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: They introduce the Reasoning Score (rscore), defined as the maximum accuracy gain under a fixed nodeediting budget, and propose Re-Schedule, which constructs approximate k-ary reasoning trees offline, simulates node edits to compute rscores, and applies an easytohard curriculum with dynamic weights during RLVR fine-tuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:36:37,863 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: They introduce the Reasoning Score (r-score), a metric measuring query difficulty from its reasoning-tree structure, and propose Re-Schedule, a curriculum algorithm that orders queries from structurally simple to complex based on the r-score.\n",
      "\n",
      "\n",
      "Question: What quantitative improvement does the Re-Schedule method achieve over baseline scheduling approaches?\n",
      "Ground truth: Re-Schedule significantly improves average accuracy on complex reasoning tasks, achieving gains of up to 3.2% over accuracy-based scheduling baselines.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:36:39,931 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: Re-Schedule achieves 47.1% accuracy versus 46.9% under a linear schedule and 48.3% versus 47.4% under a sigmoid schedule for single-node fixes, consistently outperforming baseline scheduling approaches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:36:42,017 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: Under a linear schedule, Re-Schedule achieves 47.1% versus 46.9% (+0.2%), and under a sigmoid schedule, 48.3% versus 47.4% (+0.9%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:36:44,027 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: Re-Schedule improves average accuracy on six math-reasoning benchmarks by up to 3.2%.\n",
      "\n",
      "\n",
      "Question: On which dataset and evaluation benchmarks do the authors demonstrate the effectiveness of their approach?\n",
      "Ground truth: They train on the DAPO-Math-17k dataset of integer math problems and evaluate on six benchmarks: AIME24, AIME25, AMC23, MATH-500, Minerva Math, and OlympiadBench.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:36:46,040 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: They evaluate on DAPA-Math-17K and five other standard math-reasoning benchmarks using Qwen2.5-Math-7B and Qwen2.5-7B models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:36:48,057 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: They evaluate on six math-reasoning benchmarks, including the DAPA-Math-17K dataset with Qwen2.5-Math-7B and Qwen2.5-7B.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:36:49,620 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What limitation related to the reasoning tree approximation do the authors identify?\n",
      "Ground truth: While larger values for the branching factor k and maximum depth d theoretically provide a more accurate approximation and thus a more effective r-score, they also introduce a significant computational overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:36:51,313 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:36:52,708 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:36:54,921 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "####### ..\\data\\raw\\htmls\\2510.25005v1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:37:12,764 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:37:30,473 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:37:46,220 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:37:50,137 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question: What specific problem does the paper address?\n",
      "Ground truth: The lack of theoretical foundations for counterfactual inference in cyclic structural causal models under shift-scale interventions, due to violations of unique solvability in the presence of feedback loops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:37:52,269 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: Addressing the failure of prevailing counterfactual frameworks in cyclic causal systems by providing theoretical foundations for counterfactual inference in cyclic SCMs under shift-scale interventions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:37:54,093 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: The lack of theoretical foundations for counterfactual inference in cyclic structural causal models under shift-scale interventions, caused by feedback loops violating unique solvability assumptions in existing (acyclic) frameworks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:37:55,616 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What methodology do the authors use to establish unique solvability and well-posedness of counterfactuals in cyclic SCMs?\n",
      "Ground truth: They assume a global p-contraction condition on the causal mechanism and apply Banachs fixed-point theorem to prove that both the original and shift-scale intervened twin SCMs are uniquely solvable (i.e. simple SCMs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:37:57,867 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: They impose a global -contraction condition on the causal mechanisms and apply Banachs fixed-point theorem to guarantee unique solvability of both the original and intervened twin SCMs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:38:00,108 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: They impose a global -contraction condition (<1) on the causal mechanisms and apply Banachs fixed-point theorem to prove unique solvability of both the original and shift-scale intervened twin SCMs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:38:01,867 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What quantitative bound do the authors derive for the tails of counterfactual functionals under Gaussian noise?\n",
      "Ground truth: They show that for any 1-Lipschitz functional h, P(h(X,X')E[h(X,X')]t)  exp(t/(2(1))) for t>0, so (X,X') is sub-Gaussian with proxy (1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:38:04,546 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: They derive sub-Gaussian concentration bounds for counterfactual outcomes under Gaussian noise, showing P(h(X,X')E[h(X,X')]t)  exp(t/(2(1))), i.e. a variance proxy of (1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:38:07,480 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: They show that for any 1-Lipschitz functional h, P(h(X,X')E[h(X,X')]t)  exp(t/(2(1))), so (X,X') is sub-Gaussian with variance proxy (1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:38:09,365 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What illustrative environment do the authors use to demonstrate their theory?\n",
      "Ground truth: A two-variable linear cyclic SCM modeling consumption C and income I defined by C=0.50I+1+E_C, I=0.40C+0.50+E_I with (E_C,E_I)~(0,0.04I).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:38:12,013 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: An illustrative two-variable linear cyclic SCM modeling consumption and income under Gaussian noise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:38:14,589 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: A two-variable linear cyclic SCM of consumption C and income I defined by C = 0.50I + 1 + E_C and I = 0.40C + 0.50 + E_I with (E_C,E_I)  N(0, 0.04I).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:38:16,095 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What limitation or future work do the authors identify regarding their intervention class?\n",
      "Ground truth: They only cover shift-scale interventions with bounded scale factors (|a_j|1) and do not yet address interventions with larger multiplicative gains, stochastic policies, or more general functional forms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:38:17,965 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: They do not evaluate any empirical datasets or comparative baselines.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:38:19,663 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:38:21,386 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "####### ..\\data\\raw\\htmls\\2510.25007v1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:38:40,459 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:38:47,046 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:38:54,857 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:39:04,436 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question: What specific problem does ProFees address in CPT E/M coding?\n",
      "Ground truth: It addresses the resource-intensive, inconsistent, and error-prone manual process of assigning CPT E/M codes under complex guidelines and variable coder expertise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:05,691 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: It addresses the resource-intensive, inconsistent, and error-prone manual process of assigning CPT E/M codes under complex guidelines and variable coder expertise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:06,921 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: It addresses the resource-intensive, inconsistent, and error-prone manual process of assigning CPT E/M codes under complex guidelines and variable coder expertise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:08,206 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What methodology does ProFees use for CPT E/M coding automation?\n",
      "Ground truth: ProFees employs a modular LLM-based framework combining dynamic few-shot chain-of-thought prompting, explicit LLM-based criticism (RCI), self-consistency via majority voting, and rule-based decision trees.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:10,807 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: ProFees employs a modular LLM-based framework combining dynamic few-shot chain-of-thought prompting, an LLM-based critic for explicit MDM validation, a self-consistency strategy via majority voting over parallel inferences, and a deterministic rule-based CPT decision tree.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:13,599 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: ProFees employs a modular LLM-based framework combining dynamic few-shot chain-of-thought prompting, an LLM-based MDM critic with recursive criticism & improvement, self-consistency via K parallel inferences with majority voting, and a deterministic CPT decision tree.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:15,436 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: By what percentage did ProFees improve CPT coding accuracy over the commercial coding system?\n",
      "Ground truth: ProFees achieved 36.85% higher CPT accuracy than the commercial System A.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:16,896 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: 36.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:18,274 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: 36.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:19,570 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: more than 36%\n",
      "\n",
      "\n",
      "Question: What was the size of the test dataset used to evaluate ProFees?\n",
      "Ground truth: The Test dataset comprised 99 encounters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:21,099 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:22,469 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:23,808 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What future work do the authors propose for ProFees?\n",
      "Ground truth: Future work includes extending the model to support multiple codes and CPT modifiers, and generating synthetic datasets for edge-case testing and to enrich the VDB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:26,770 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: Multi-code support and synthetic edge-case generation to enhance generalizability.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:29,367 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: Future work includes extending multi-code support and synthetic edge-case generation to improve generalizability.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:30,929 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "####### ..\\data\\raw\\htmls\\2510.25014v1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:39:48,835 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:39:55,346 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:40:03,383 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:40:16,080 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question: What specific challenge does this paper address in using LLMs for in-game trading?\n",
      "Ground truth: The paper addresses the core tension between LLMs' creative flexibility and the semi-structured procedures of commercial transactions in in-game trading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:17,924 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: The paper addresses the core tension between LLMs' creative flexibility and the semi-structured procedures of commercial transactions in in-game trading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:20,330 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: LLMs fail to enforce the semi-structured trading proceduresbrowse, offer, review, confirmleading to skipped steps and unwanted purchases.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:22,258 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: The core tension between LLMs creative flexibility and the procedural demands of in-game trading, namely their failure to follow essential procedural flows in rule-governed trading systems\n",
      "\n",
      "\n",
      "Question: What methodology does the paper introduce to enforce procedural compliance?\n",
      "Ground truth: The paper introduces Autoregressive State-Tracking Prompting (ASTP), a prompting methodology that makes state-tracking an explicit, autoregressive process embedded in a structured Prime-Guide-Enforce workflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:23,186 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: The paper introduces Autoregressive State-Tracking Prompting (ASTP), a prompting methodology that makes state-tracking an explicit, autoregressive process embedded in a structured Prime-Guide-Enforce workflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:26,049 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: Autoregressive State-Tracking Prompting (ASTP), a Prime-Guide-Enforce workflow that requires explicit inference and emission of the previous dialogue state before each turn, paired with placeholder-based post-processing for numeric precision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:28,031 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: Autoregressive State-Tracking Prompting (ASTP)\n",
      "\n",
      "\n",
      "Question: By how much did ASTP improve procedural compliance according to the results?\n",
      "Ground truth: ASTP increased adherence to key safeguards from 78.1% to 99.6%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:29,191 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: ASTP increased adherence to key safeguards from 78.1% to 99.6%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:31,358 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: Procedural compliance improved from 78.1% to 99.6%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:32,943 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What environment was used to evaluate the proposed method?\n",
      "Ground truth: All experiments utilized a virtual player LLM interacting with an LLM-driven NPC over 300 dialogues across two scenarios: Specific Item Purchase and Item Recommendation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:34,220 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:37,188 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: It was evaluated on 300 in-game trading dialogues from two scenarios using JSON-formatted world data (52 items) and a 20-item merchant inventory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:39,579 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What future work do the authors suggest?\n",
      "Ground truth: Future work should investigate the scalability of ASTP across a larger number of states and more complex transition rules.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:40,797 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: Future work should investigate the scalability of ASTP across a larger number of states and more complex transition rules.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:41,984 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:43,069 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "####### ..\\data\\raw\\htmls\\2510.25065v1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:40:54,596 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:41:05,940 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:41:14,833 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:41:21,674 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question: What specific problem does PM4GRPO aim to address?\n",
      "Ground truth: Existing GRPO-inspired methods focus solely on optimizing final answers and neglect the underlying reasoning processes, resulting in suboptimal behaviors such as unnecessary verbosity and accidental correctness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:41:23,412 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: Existing GRPO-based RL post-training methods optimize only final answers or surface-level text features, neglecting the chain-of-thought process and encouraging verbosity, speculative leaps, or accidental correctness without genuine understanding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:41:25,373 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: Existing GRPO-based post-training methods optimize only final answers or surface text and neglect chain-of-thought, encouraging verbosity, speculation, or accidental correctness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:41:27,776 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: PM4GRPO addresses the limitation of outcome-centric reward schemes in GRPO-based post-training, which focus only on final answers/formats and neglect the underlying multi-step reasoning process.\n",
      "\n",
      "\n",
      "Question: What methodology does PM4GRPO use to integrate reasoning process alignment into GRPO-based post-training?\n",
      "Ground truth: PM4GRPO uses Process Mining techniquesinductive miner to build process models from policy reasoning traces and alignment-based conformance checking to measure their alignment with a teacher models reasoning as a conformance reward in GRPO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:41:30,627 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: PM4GRPO integrates Process Mining into GRPO by using the Inductive Miner to discover a process model from the students generated reasoning traces and alignment-based conformance checking against the teachers traces to compute an F1-based sequence-level reward, which is then combined with standard format and answer rewards under the GSPO objective.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:41:33,039 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: PM4GRPO extends Group Sequence Policy Optimization by applying Process Mining: it uses the Inductive Miner to infer a process model from policy-generated reasoning sequences and alignment-based conformance checking to compute an F1 conformance reward measuring alignment with a teachers reasoning traces.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:41:35,718 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: It uses process mining techniques to compute a scalar conformance rewardmeasuring how closely the policy models reasoning traces align with those of a pretrained teacher modeland incorporates this reward into GRPO.\n",
      "\n",
      "\n",
      "Question: What MATH500 accuracy did the 7B-scale PM4GRPO model achieve?\n",
      "Ground truth: The 7B-scale PM4GRPO model achieved 91.1% accuracy on the MATH500 benchmark.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:41:37,083 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: 91.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:41:38,848 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: 91.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:41:40,176 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: Which dataset was used to train the PM4GRPO models?\n",
      "Ground truth: The models were trained on the DeepMath-103k dataset of mathematical problems with solutions generated by DeepSeek-R1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:41:41,784 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:41:43,426 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:41:44,847 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What future research direction do the authors suggest?\n",
      "Ground truth: They suggest exploring Process Mining techniques for quantitatively evaluating reasoning procedures as processes in reinforcement learning for large reasoning models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:41:48,579 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: They suggest leveraging process-aware reward design to develop more robust reinforcement learning strategies for large reasoning models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:41:50,052 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:41:52,319 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "####### ..\\data\\raw\\htmls\\2510.25091v1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:42:14,551 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:42:27,720 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:42:37,284 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:42:45,238 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question: What specific problem does the paper address?\n",
      "Ground truth: We formulate the d d -day-ahead stock movement prediction as a binary classification problem, aiming to forecast whether the closing price of each constituent stock within the market index will rise after d d trading days.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:42:47,102 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:42:49,700 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: Stock movement prediction in the presence of low signal-to-noise ratios, non-stationarity, dynamic inter-stock dependencies, and multimodal heterogeneity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:42:51,219 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What methodology is proposed to solve this problem?\n",
      "Ground truth: We propose a novel multi-modal architecture that synergistically integrates multi-context hypergraph modeling, LLM-enhanced semantic reasoning, and style-structure expert specialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:42:54,236 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: A unified multi-modal architecture called H3M-SSMoEs, which integrates a hierarchical multi-context hypergraph, a frozen Llama-3.2-1B LLM with lightweight adapters for deep semantic alignment, and a Style-Structured Mixture-of-Experts module that sparsely activates specialized experts based on market regimes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:42:56,743 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: H3M-SSMoEs: a hierarchical multi-context hypergraph combined with a frozen Llama-3.2-1B LLM with lightweight adapters and a Style-Structured Mixture-of-Experts module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:42:59,426 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: H3M-SSMoEs: a Hypergraph-based Multimodal architecture integrating a Multi-Context Hypergraph for spatiotemporal and inter-stock relational learning, an LLM-enhanced reasoning module for semantic fusion of quantitative and textual data, and a Style-Structured Mixture of Experts for regime-aware specialization.\n",
      "\n",
      "\n",
      "Question: What quantitative results demonstrate the performance of the proposed method?\n",
      "Ground truth: Extensive experiments on the DJIA, NASDAQ 100, and S&P 100 indices demonstrate our method's state-of-the-art performance, achieving the highest risk-adjusted returns with Sharpe ratios of 1.585, 2.100, and 1.351, and Calmar ratios of 3.377, 4.380, and 2.075, respectively, while maintaining the lowest maximum drawdowns (14.81%, 16.17%, and 14.27%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:43:02,197 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: On the DJIA, H3M-SSMoEs achieved a 50.00% annual return and a Sharpe ratio of 1.585, representing a 57.7% improvement over the strongest baseline.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:43:04,250 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: Backtesting on DJIA yields a 50.00% annual return and a Sharpe ratio of 1.585, a 57.7% improvement over the strongest baseline.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:43:05,947 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: On which datasets or environments was the proposed method evaluated?\n",
      "Ground truth: We evaluated our method on three major stock indices: DJIA, NASDAQ 100, and S&P 100, using data from January 1, 2020 to August 31, 2025, with a 7:1:2 split into training, validation, and testing sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:43:07,481 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: The model was evaluated on the Dow Jones Industrial Average (DJIA).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:43:09,469 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: Backtesting on the Dow Jones Industrial Average (DJIA).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:43:10,724 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What limitation or future work does the paper identify?\n",
      "Ground truth: A promising research direction lies in developing unified frameworks that jointly incorporate hypergraph-informed structural priors, LLM-based semantic reasoning, and specialized MoE processing, balancing representational richness with efficiency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:43:13,160 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: The frameworks complexity and data diversity requirements may challenge real-time deployment and generalization across markets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:43:15,233 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: The models complexity and data demands may hinder real-time deployment and cross-market generalization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:43:16,770 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "####### ..\\data\\raw\\htmls\\2510.25101v1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:43:37,702 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:43:55,248 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:44:05,643 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:44:17,293 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question: What specific limitation of existing agentic KBQA methods does this paper address?\n",
      "Ground truth: The paper addresses the reliance on process supervision in existing agentic KBQA methods, which provides weak incentives for autonomous exploration and leads to limited robustness and flexibility.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:19,493 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: Reliance on process-supervised, idealized, gold-logical-form reasoning trajectories that are singular and error-free, resulting in brittleness, poor robustness to noisy tool interactions, and limited flexibility to explore alternative reasoning paths.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:21,412 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: The paper addresses the reliance on process-supervised gold logical-form trajectories in existing agentic KBQA methods, which leads to brittleness and limited flexibility.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:23,868 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: The reliance on process supervision, which offers weak incentives for exploration and fails to strengthen agentic reasoning.\n",
      "\n",
      "\n",
      "Question: What methodology does KnowCoder-A1 use to enhance agentic reasoning in KBQA?\n",
      "Ground truth: KnowCoder-A1 adopts a multi-stage curriculum reinforcement learning approach that relies mainly on outcome-only supervision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:25,262 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: A multi-stage curriculum reinforcement learning framework trained exclusively with outcome-only supervision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:27,132 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: KnowCoder-A1 uses a multi-stage curriculum reinforcement learning framework trained solely with outcome-only supervision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:28,779 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: A multi-stage curriculum reinforcement learning approach trained under outcome-only supervision with an easy-to-hard curriculum.\n",
      "\n",
      "\n",
      "Question: What quantitative performance does KnowCoder-A1 achieve on the GrailQA benchmark?\n",
      "Ground truth: Using 12 less training data, it achieves an F1 score of 80.5% on GrailQA, achieving a 3.3% relative improvement over KBQA-o1, the previous SOTA agentic-based approach.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:30,885 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: An F1 score of 80.5% on the generalization-focused GrailQA dataset, with a 3.3% relative improvement over the prior KBQA-o1 baseline.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:33,165 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: It achieves an F1 score of 80.5% on GrailQA, representing a 3.3% relative improvement over the KBQA-o1 baseline.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:35,622 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: Up to an 11.1% relative improvement on the zero-shot subset of GrailQA while using only one-twelfth of the training data.\n",
      "\n",
      "\n",
      "Question: On which datasets is KnowCoder-A1 evaluated?\n",
      "Ground truth: KnowCoder-A1 is evaluated on three widely-used KBQA datasets: WebQSP, CWQ, and GrailQA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:37,066 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: WebQSP, CWQ, and GrailQA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:38,466 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: KnowCoder-A1 is evaluated on the WebQSP, CWQ and GrailQA datasets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:40,068 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What future research directions do the authors suggest?\n",
      "Ground truth: Future work may investigate more advanced reflection mechanisms to mitigate remaining error types and extend the curriculum strategy to other complex, agent-based reasoning tasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:42,390 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: Investigating advanced reflection mechanisms to address residual error types and extending the curriculum reinforcement learning paradigm to other complex interactive AI tasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:43,842 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:45,291 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "####### ..\\data\\raw\\htmls\\2510.25179v1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:44:57,073 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:45:07,737 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:45:14,360 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:45:21,218 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question: What specific problem does this paper address?\n",
      "Ground truth: Defending large vision-language models against cross-modal adversarial attacks that exploit visual vulnerabilities and modality shifts in semantic meaning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:45:23,300 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: Defending LVLMs against sophisticated cross-modal adversarial attacks, including pixel-level perturbations, hidden intent in benign textimage combinations, and ensemble strategies that evade existing defenses.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:45:25,927 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: Vulnerability of LVLMs to pixel-level adversarial perturbations, hidden intent in benign textimage pairs, and ensemble attacks that bypass rule-based defenses or require costly computation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:45:28,978 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: Defending multimodal systems against jailbreak attacks.\n",
      "\n",
      "\n",
      "Question: What methodology do the authors propose to improve LVLM safety?\n",
      "Ground truth: A model-agnostic Agentic Moderation Framework that coordinates specialized Shield, Responder, Evaluator, and Reflector agents in an iterative, collaborative workflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:45:31,329 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: A model-agnostic Agentic Moderation framework that coordinates specialized SHIELD, Responder, Evaluator, and Reflection agents in an iterative, collaborative workflow without retraining the underlying LVLM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:45:34,023 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: A model-agnostic Agentic Moderation framework that uses a Coordinator to orchestrate four specialist agentsSHIELD, Responder, Evaluator, and Reflectorin an iterative collaborative workflow without retraining the underlying LVLM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:45:36,749 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: A model-agnostic framework leveraging dynamic, cooperative agents (Shield, Responder, Evaluator, Reflector) for context-aware, interpretable moderation.\n",
      "\n",
      "\n",
      "Question: What quantitative improvements does Agentic Moderation achieve?\n",
      "Ground truth: It reduces Attack Success Rate by 719% while keeping Non-Following Rate stable and improving Refusal Rate by 420%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:45:38,717 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: A 17% increase in refusal rate on LLaMA with only 0.015 seconds of preprocessing overhead per query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:45:40,823 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: It boosts refusal rates by 17% over static rule-based and classifier baselines with only a 0.015-second preprocessing overhead per query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:45:42,661 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: It reduces Attack Success Rate by 719%, maintains a stable Non-Following Rate, and improves Refusal Rate by 420%.\n",
      "\n",
      "\n",
      "Question: On which datasets and with what sampling strategy is the framework evaluated?\n",
      "Ground truth: On five cross-modality adversarial safety datasetsAdvBench, FigStep, Flow-JD, MMSafety, and SIUOusing a random sample of 100 instances from each.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:45:44,494 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:45:46,087 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:45:47,539 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What are the main limitations of the framework and proposed future work?\n",
      "Ground truth: The multi-agent design trades off safety robustness with increased computational cost and latency, and future work will explore adaptive agent scheduling and cost-aware coordination strategies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:45:49,316 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: The absence of adaptive coordination among agents, which the authors identify as a direction for future development.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:45:51,397 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: The lack of adaptive coordination among agents is the primary limitation, with future work aiming to develop adaptive coordination strategies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:45:53,214 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "####### ..\\data\\raw\\htmls\\2510.25205v1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:46:28,731 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:46:39,728 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:46:52,619 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:47:02,744 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question: What specific objective is addressed by this paper?\n",
      "Ground truth: Our objective is to adaptively reduce the energy consumption of the autonomous vehicle under a specific perception accuracy, while maintaining good driving performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:04,609 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: Our objective is to adaptively reduce the energy consumption of the autonomous vehicle under a target perception accuracy while maintaining strong driving performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:08,907 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: Our objective is to adaptively reduce the energy consumption of the autonomousdriving perception system under a specific perception accuracy, while maintaining good driving performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:10,998 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: To adaptively reduce energy consumption of autonomous vehicle perception while maintaining desired perception accuracy and good driving performance.\n",
      "\n",
      "\n",
      "Question: What methodology is proposed in this study?\n",
      "Ground truth: To tackle these challenges, we propose an energy-efficient autonomous driving framework, called EneAD, which includes an adaptive perception module and a robust decision module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:13,143 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: We propose an energy-efficient autonomous driving framework called EneAD, which comprises an adaptive perception module and a regularized reinforcement-learning decision module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:15,806 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: We propose EneAD, an energyefficient framework that adaptively configures perception (model choice, framerate, interpolation) via a lightweight uncertainty-aware classifier and multi-objective Bayesian optimization, and solves driving as a regularized MDP with P-DQNstyle actor and value networks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:17,246 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: An energy-efficient autonomous driving framework called EneAD, which includes an adaptive perception module and a robust decision module.\n",
      "\n",
      "\n",
      "Question: What quantitative improvements does EneAD achieve in perception consumption and driving range?\n",
      "Ground truth: To sum up, our framework EneAD can achieve a 1.9-3.5 reduction of perception consumption, a slight reduction of the driving system, and a 3.9%-8.5% increase of driving range.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:20,935 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: EneAD achieves a 1.93.5 reduction in perception energy consumption and a 3.9%8.5% increase in driving range.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:22,677 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: EneAD achieves a 1.93.5 reduction in perception energy and a 3.9%8.5% increase in driving range.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:24,957 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: 1.93.5 reduction in perception energy consumption, and 3.9%8.5% increase in driving range.\n",
      "\n",
      "\n",
      "Question: On what simulation environment is the framework evaluated?\n",
      "Ground truth: We simulate the entire autonomous driving pipeline on the Carla simulator, which is a widely used project focused on creating a publicly available virtual environment for autonomous driving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:26,360 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:27,559 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:29,223 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What limitation or future work is identified regarding the highest-difficulty scenarios?\n",
      "Ground truth: To address it, more research breakthroughs in autonomous driving perception models are needed in the future.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:31,206 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:32,823 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:34,744 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "####### ..\\data\\raw\\htmls\\2510.25223v1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:47:50,683 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:48:02,055 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:48:12,333 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2026-01-12 23:48:18,687 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question: What specific problem does the FELA system aim to solve?\n",
      "Ground truth: Automated feature engineering on industrial-scale event log data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:48:19,993 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: Automated feature engineering on industrial-scale event log data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:48:21,455 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: Automating feature engineering for massive, heterogeneous industrial event logs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:48:22,612 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: Automated feature engineering on industrial-scale event log data.\n",
      "\n",
      "\n",
      "Question: How does FELA manage the complexity of automated feature engineering according to its architecture?\n",
      "Ground truth: FELA employs multiple LLM-based agents with specialized roles that collaborate to manage the complexity of automated feature engineering.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:48:24,686 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: FELA orchestrates specialized LLM agents (idea agents, code agents, critic agents, evaluation agent) via a hierarchical ideafeature knowledge structure and an agentic evolution algorithm to manage complexity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:48:26,554 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: By using a multi-agent framework of specialized LLM agents (idea agents, code agents, critic agents) orchestrated via a hierarchical ideafeature knowledge structure and agentic evolution algorithm.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:48:27,819 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: FELA employs multiple LLM-based agents with specialized roles that collaborate to manage the complexity of automated feature engineering.\n",
      "\n",
      "\n",
      "Question: What AUC improvement did FELA achieve on the Taobao dataset compared to LLM-FE?\n",
      "Ground truth: A notable AUC improvement from 0.641 to 0.653 over LLM-FE.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:48:29,646 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: AUC improvement from 0.641 to 0.653 on the Taobao conversion prediction task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:48:31,182 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: An AUC increase from 0.641 to 0.653.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:48:33,668 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: Which datasets were used to evaluate the FELA system?\n",
      "Ground truth: Three real-world datasets are adopted for evaluation, including Diabetes Health Indicator Dataset (Dia), Tabao Conversion Prediction Data (Taobao), and the User Churn Data in Tencent Game Platform (Tencent).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:48:35,458 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: ['Taobao conversion prediction', 'Tencent user churn prediction']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:48:37,289 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: Taobao conversion prediction dataset and Tencent user churn prediction dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:48:38,862 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "\n",
      "\n",
      "Question: What future extensions of FELA are suggested by the authors?\n",
      "Ground truth: Future work will extend FELA toward broader applications, including multimodal data, dynamic environments, and tighter human-in-the-loop collaboration to further enhance controllability, scalability, and domain alignment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:48:41,639 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary answer: Enhancing controllability, scalability, and cross-domain applicability.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:48:43,124 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined summary answer: NOT MENTIONED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:48:44,527 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract answer: NOT MENTIONED\n",
      "RAG Summary Recall: 60.00%\n",
      "RAG Refined Summary Recall: 60.00%\n",
      "Original Abstract Recall: 36.00%\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for paper_id, paper_content in papers.items():\n",
    "    print(\"#######\", paper_id)\n",
    "    # 1. Generate the Exam (using Full Text)\n",
    "    exam_json = build_exam_questions(client=client, \n",
    "                                     prompt_template=EXAMINER_PROMPT, \n",
    "                                     #full_text=paper_content.replace())\n",
    "                                     full_text=\"\\n\".join([v for v in document_sections[paper_id].values()])\n",
    "                                    )\n",
    "    questions = json.loads(exam_json)\n",
    "    #print(questions)\n",
    "    \n",
    "    # Test summary answers\n",
    "    summary_answers = build_exam_answers(client=client, \n",
    "                                         prompt_template=STUDENT_PROMPT, \n",
    "                                         summary_text=rag_summaries_vs_abstract[paper_id][\"v1_summary\"], \n",
    "                                         questions=questions)\n",
    "    summary_answers = json.loads(summary_answers)\n",
    "\n",
    "    # Test summary answers\n",
    "    refined_summary_answers = build_exam_answers(client=client, \n",
    "                                         prompt_template=STUDENT_PROMPT, \n",
    "                                         summary_text=rag_summaries_vs_abstract[paper_id][\"refined_summary\"], \n",
    "                                         questions=questions)\n",
    "    refined_summary_answers = json.loads(refined_summary_answers)\n",
    "    \n",
    "    # Test abstract answers\n",
    "    baseline_answers = build_exam_answers(client=client, \n",
    "                                          prompt_template=STUDENT_PROMPT, \n",
    "                                          summary_text=rag_summaries_vs_abstract[paper_id][\"abstract\"], \n",
    "                                          questions=questions)\n",
    "    baseline_answers = json.loads(baseline_answers)\n",
    "    \n",
    "    # 4. Grading\n",
    "    summary_score = 0\n",
    "    refined_summary_score = 0\n",
    "    abstract_score = 0\n",
    "    \n",
    "    for i, q in enumerate(questions):\n",
    "        print(\"\\n\")\n",
    "        print(f\"Question: {q['question']}\")\n",
    "        print(f\"Ground truth: {q['answer']}\")\n",
    "        \n",
    "        summary_grade = build_evaluation(client=client,\n",
    "                                         prompt_template=GRADER_PROMPT, \n",
    "                                        question=q['question'], \n",
    "                                        ground_truth=q['answer'], \n",
    "                                        answer=summary_answers[i])\n",
    "        print(f\"Summary answer: {summary_answers[i]}\")\n",
    "        if \"1\" in summary_grade: \n",
    "            summary_score += 1\n",
    "\n",
    "        refined_summary_grade = build_evaluation(client=client,\n",
    "                                         prompt_template=GRADER_PROMPT, \n",
    "                                        question=q['question'], \n",
    "                                        ground_truth=q['answer'], \n",
    "                                        answer=refined_summary_answers[i])\n",
    "        print(f\"Refined summary answer: {refined_summary_answers[i]}\")\n",
    "        if \"1\" in refined_summary_grade: \n",
    "            refined_summary_score += 1\n",
    "        \n",
    "        abstract_grade = build_evaluation(client=client,\n",
    "                                          prompt_template=GRADER_PROMPT, \n",
    "                                        question=q['question'], \n",
    "                                        ground_truth=q['answer'], \n",
    "                                        answer=baseline_answers[i])\n",
    "        print(f\"Abstract answer: {baseline_answers[i]}\")\n",
    "        if \"1\" in abstract_grade: \n",
    "            abstract_score += 1\n",
    "\n",
    "    results.append({\n",
    "        \"paper_id\": paper_id,\n",
    "        \"summary_recall\": summary_score / 5.0,\n",
    "        \"refined_summary_recall\": summary_score / 5.0,\n",
    "        \"abstract_recall\": abstract_score / 5.0\n",
    "    })\n",
    "    print()\n",
    "    \n",
    "# Calculate Average Improvement\n",
    "avg_summary_recall = sum(r['summary_recall'] for r in results) / len(results)\n",
    "avg_refined_summary_recall = sum(r['refined_summary_recall'] for r in results) / len(results)\n",
    "avg_abstract_recall = sum(r['abstract_recall'] for r in results) / len(results)\n",
    "\n",
    "print(f\"RAG Summary Recall: {avg_summary_recall:.2%}\")\n",
    "print(f\"RAG Refined Summary Recall: {avg_refined_summary_recall:.2%}\")\n",
    "print(f\"Original Abstract Recall: {avg_abstract_recall:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c78ed36-98c6-4313-b1d8-cfd50b1b5a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
