{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c92c8678-3034-4449-bc96-ce577387b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests as rq\n",
    "from urllib.parse import urljoin\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bcf7ce8-c974-4dba-8079-0f99f900afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_urls(navigation: bs4.element.ResultSet, n: int) -> list:\n",
    "    '''\n",
    "    Obtains the url link to each paper which appears in the navigation list.\n",
    "    '''\n",
    "    paper_urls = []\n",
    "    \n",
    "    for i, item in enumerate(navigation):\n",
    "        id_ = item.select_one(\"a[title='Abstract'][id]\")\n",
    "        html_tag = item.select_one(\"a[title='View HTML'][id^='html-']\")\n",
    "        html_url = urljoin(arxiv_url, html_tag[\"href\"]) if html_tag else None\n",
    "    \n",
    "        if not html_url:\n",
    "            continue\n",
    "        else:\n",
    "            paper_urls.append(html_url)\n",
    "\n",
    "        if len(paper_urls) >= n_papers:\n",
    "            break\n",
    "\n",
    "    return paper_urls\n",
    "\n",
    "\n",
    "def get_title(soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Gets the text content of the title tag.\n",
    "    '''\n",
    "    title = soup.find(\"title\").get_text()\n",
    "    \n",
    "    return title\n",
    "\n",
    "\n",
    "def get_abstract(soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Gets the text content of the abstract tag.\n",
    "    '''\n",
    "    abstract_h6 = soup.find(\"h6\", class_=\"ltx_title ltx_title_abstract\")\n",
    "    p = abstract_h6.find_next(\"p\", class_=\"ltx_p\")\n",
    "    abstract_text = p.get_text()\n",
    "    \n",
    "    return abstract_text\n",
    "\n",
    "\n",
    "def check_file_exists(path: str) -> bool:\n",
    "    '''\n",
    "    Check file exists.\n",
    "    '''\n",
    "    return os.path.exists(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ffb4161-ec2c-4c48-9d0f-b16f50a37137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data path if necessary\n",
    "data_path = \"../data\"\n",
    "\n",
    "if not Path(data_path).exists():\n",
    "    Path(data_path).mkdir()\n",
    "    \n",
    "    (Path(data_path)/\"raw\").mkdir()\n",
    "    (Path(data_path)/\"raw\"/\"htmls\").mkdir()\n",
    "    (Path(data_path)/\"raw\"/\"abstracts\").mkdir()\n",
    "    (Path(data_path)/\"raw\"/\"parsed_sections\").mkdir()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "924b9819-9e99-428f-af99-1d3e85338a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying https://arxiv.org/list/cs.AI/recent?skip=0&show=1000\n"
     ]
    }
   ],
   "source": [
    "# Set the parameters for scraping the website\n",
    "ARXIV_BASE_URL = \"https://arxiv.org/list\"\n",
    "arxiv_topic = \"/cs.AI/recent?skip=0&show=1000\"\n",
    "arxiv_url = f\"{ARXIV_BASE_URL}{arxiv_topic}\"\n",
    "print(f\"Querying {arxiv_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60d3dff3-7725-473c-8a48-27f6c3fe2004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Query the recently uploaded papers list\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "response = rq.get(arxiv_url, headers = headers)\n",
    "response_html = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afddfa54-4099-47d9-b0ca-7fa1a5a7465e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Obtain the list of items from the papers list\n",
    "main_soup = BeautifulSoup(response_html, \"html.parser\")\n",
    "navigation = main_soup.select(\"dl > dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c5554e5-d750-4d86-a7cb-67d6ced25674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Obtain a list of n links to the recent papers for the chosen topic\n",
    "# TO DO: Implement a handler for when the amount of documents is less than n due to issues with the HTML content of the linked page.\n",
    "n_papers = 60\n",
    "paper_urls = get_paper_urls(navigation=navigation, n=n_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "execution_count": 10,
   "execution_count": null,
   "id": "6afae102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursively extract sections from soup representation of html\n",
    "def get_sections(tag: BeautifulSoup):\n",
    "    section_tags = tag.find_all(\"section\", recursive=False)\n",
    "    sections = []\n",
    "\n",
    "\n",
    "    for section_tag in section_tags:\n",
    "\n",
    "        paragraphs = [\n",
    "        p.get_text(\" \", strip=True)\n",
    "        for p in section_tag.find_all(\"p\")\n",
    "        ]\n",
    "        section_dict = {\n",
    "            \"title\": section_tag.find([\"h1\",\n",
    "                                       \"h2\",\n",
    "                                       \"h3\",\n",
    "                                       \"h4\",\n",
    "                                       \"h5\",\n",
    "                                       \"h6\",\n",
    "                                       \"h7\"]).get_text().strip(),\n",
    "            \"paragraphs\": \"\\n\".join(paragraphs),\n",
    "            \"subsections\": get_sections(section_tag)\n",
    "        }\n",
    "        sections.append(section_dict)\n",
    "    return sections\n",
    "\n",
    "    return get_sections(get_sections(\n",
    "        tag.find(\"html\", recursive=False).find(\"body\",recursive=False).find(\"div\",class_=\"ltx_page_main\", recursive=False).find(\"div\",class_=\"ltx_page_content\", recursive=False).find(\"article\", recursive=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10191187-4cf3-4968-b39b-088c37b13044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both files for 2510.25758v1 already downloaded, skipping.\n",
      "Both files for 2510.25724v1 already downloaded, skipping.\n",
      "Both files for 2510.25679v1 already downloaded, skipping.\n",
      "Both files for 2510.25668v1 already downloaded, skipping.\n",
      "Both files for 2510.25612v1 already downloaded, skipping.\n",
      "Both files for 2510.25588v1 already downloaded, skipping.\n",
      "Both files for 2510.25518v1 already downloaded, skipping.\n",
      "Both files for 2510.25517v1 already downloaded, skipping.\n",
      "Both files for 2510.25510v1 already downloaded, skipping.\n",
      "Both files for 2510.25504v1 already downloaded, skipping.\n",
      "Both files for 2510.25445v1 already downloaded, skipping.\n",
      "Both files for 2510.25388v1 already downloaded, skipping.\n",
      "Both files for 2510.25320v1 already downloaded, skipping.\n",
      "Both files for 2510.25232v1 already downloaded, skipping.\n",
      "Both files for 2510.25223v1 already downloaded, skipping.\n",
      "Both files for 2510.25205v1 already downloaded, skipping.\n",
      "Both files for 2510.25179v1 already downloaded, skipping.\n",
      "Both files for 2510.25101v1 already downloaded, skipping.\n",
      "Both files for 2510.25091v1 already downloaded, skipping.\n",
      "Both files for 2510.25065v1 already downloaded, skipping.\n",
      "Both files for 2510.25014v1 already downloaded, skipping.\n",
      "Both files for 2510.25007v1 already downloaded, skipping.\n",
      "Both files for 2510.25005v1 already downloaded, skipping.\n",
      "Both files for 2510.24832v1 already downloaded, skipping.\n",
      "Both files for 2510.25770v1 already downloaded, skipping.\n",
      "Both files for 2510.25732v1 already downloaded, skipping.\n",
      "Both files for 2510.25731v1 already downloaded, skipping.\n",
      "Both files for 2510.25729v1 already downloaded, skipping.\n",
      "Both files for 2510.25694v1 already downloaded, skipping.\n",
      "Both files for 2510.25683v1 already downloaded, skipping.\n",
      "Both files for 2510.25662v1 already downloaded, skipping.\n",
      "Both files for 2510.25634v1 already downloaded, skipping.\n",
      "Both files for 2510.25626v1 already downloaded, skipping.\n",
      "Both files for 2510.25616v1 already downloaded, skipping.\n",
      "Both files for 2510.25609v1 already downloaded, skipping.\n",
      "Both files for 2510.25602v1 already downloaded, skipping.\n",
      "Both files for 2510.25595v1 already downloaded, skipping.\n",
      "Both files for 2510.25590v1 already downloaded, skipping.\n",
      "Both files for 2510.25577v1 already downloaded, skipping.\n",
      "Both files for 2510.25563v1 already downloaded, skipping.\n",
      "Both files for 2510.25557v1 already downloaded, skipping.\n",
      "\u001b[93m Skipping 2510.25531v1 as it does not have an abstract. \u001b[0m\n",
      "Downloading https://arxiv.org/html/2510.25512v1 \n",
      "\t Title: FaCT: Faithful Concept Traces for Explaining Neural Network Decisions\n",
      "Wrote file ../data/raw/htmls/2510.25512v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25512v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25506v1 \n",
      "\t Title: Reflections on the Reproducibility of Commercial LLM Performance in Empirical Software Engineering Studies\n",
      "Wrote file ../data/raw/htmls/2510.25506v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25506v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25502v1 \n",
      "\t Title: TempoPFN: Synthetic Pre-training of Linear RNNs for Zero-shot Time Series Forecasting\n",
      "Wrote file ../data/raw/htmls/2510.25502v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25502v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25458v1 \n",
      "\t Title: 1 INTRODUCTION\n",
      "Wrote file ../data/raw/htmls/2510.25458v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25458v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25441v1 \n",
      "\t Title: Grounded in Reality: Learning and Deploying Proactive LLM from Offline Logs\n",
      "Wrote file ../data/raw/htmls/2510.25441v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25441v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25428v1 \n",
      "\t Title: Alibaba International E-commerce Product Search Competition DcuRAGONs Team Technical Report\n",
      "Wrote file ../data/raw/htmls/2510.25428v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25428v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25426v1 \n",
      "\t Title: Implicature in Interaction: Understanding Implicature Improves Alignment in Human–LLM InteractionPre-print article, Manuscript under review\n",
      "Wrote file ../data/raw/htmls/2510.25426v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25426v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25420v1 \n",
      "\t Title: Improving Temporal Consistency and Fidelity at Inference-time in Perceptual Video Restoration by Zero-shot Image-based Diffusion Models\n",
      "Wrote file ../data/raw/htmls/2510.25420v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25420v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25416v1 \n",
      "\t Title: Adaptive End-to-End Transceiver Design for NextG Pilot-Free and CP-Free Wireless Systems\n",
      "Wrote file ../data/raw/htmls/2510.25416v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25416v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25409v1 \n",
      "\t Title: BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains\n",
      "Wrote file ../data/raw/htmls/2510.25409v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25409v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25404v1 \n",
      "\t Title: GPTOpt: Towards Efficient LLM-Based Black-Box Optimization\n",
      "Wrote file ../data/raw/htmls/2510.25404v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25404v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25386v1 \n",
      "\t Title: Integrating Legal and Logical Specifications in Perception, Prediction, and Planning for Automated Driving: A Survey of Methods\n",
      "Wrote file ../data/raw/htmls/2510.25386v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25386v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25378v1 \n",
      "\t Title: Hallucinations in Bibliographic Recommendation: Citation Frequency as a Proxy for Training Data Redundancy\n",
      "Wrote file ../data/raw/htmls/2510.25378v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25378v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25368v1 \n",
      "\t Title: Position: Biology is the Challenge Physics-Informed ML Needs to Evolve\n",
      "Wrote file ../data/raw/htmls/2510.25368v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25368v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25366v1 \n",
      "\t Title: A Convexity-dependent Two-Phase Training Algorithm for Deep Neural Networks\n",
      "Wrote file ../data/raw/htmls/2510.25366v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25366v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25340v1 \n",
      "\t Title: Multi-party Agent Relation Sampling for Multi-party Ad Hoc Teamwork\n",
      "Wrote file ../data/raw/htmls/2510.25340v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25340v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25327v1 \n",
      "\t Title: MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding\n",
      "Wrote file ../data/raw/htmls/2510.25327v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25327v1.txt\n",
      "Downloading https://arxiv.org/html/2510.25319v1 \n",
      "\t Title: 4-Doodle: Text to 3D Sketches that Move!\n",
      "Wrote file ../data/raw/htmls/2510.25319v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.25319v1.txt\n"
      "Downloading https://arxiv.org/html/2510.24388v1 \n",
      "\t Title: A Characterization of Egalitarian and Proportional Sharing Principles: An Efficient Extension Operator Approach1footnote 11footnote 1We thank Phillipe Solal, Sylvain Ferrières Sylvain Béal, Juan D. Moreno-Ternero, Toru Hokari, Stéphane Gonzalez, David Lowing, Kevin Techker, Susumu Cato, Takashi Ui, Nobuo Koida, Shintaro Miura, Florian Navarro, Hendrik Rommeswinkel, and participants in EAGT 2024, Summer workshop 2024, RISS workshop 2025 in Kansai University, Prof. Koichi Tadenuma retirement conference, Université Marie et Louis Pasteur, Hitotsubashi University, Kwansei-gakuin Univeristy, SING 2025, University of Saint-Etienne, and Networks and Games seminars at CES for helpful comments. Nakada acknowledges the financial support from Japan Society for the Promotion of Science KAKENHI: No.19K13651, 20KK0036, and 25K16606. Koriyama acknowledges the financial support from Investissements d’Avenir, ANR-11-IDEX-0003/Labex Ecodec/ANR-11-LABX-0047. All remaining errors are our own.\n",
      "Wrote file ../data/raw/htmls/2510.24388v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.24388v1.txt\n",
      "Downloading https://arxiv.org/html/2510.24266v1 \n",
      "\t Title: 1 Introduction\n",
      "Wrote file ../data/raw/htmls/2510.24266v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.24266v1.txt\n",
      "Downloading https://arxiv.org/html/2510.23951v1 \n",
      "\t Title: Strategic Learning with Asymmetric Rationality\n",
      "Wrote file ../data/raw/htmls/2510.23951v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.23951v1.txt\n",
      "Downloading https://arxiv.org/html/2510.23628v1 \n",
      "\t Title: Matchings Under Biased and Correlated Evaluations\n",
      "Wrote file ../data/raw/htmls/2510.23628v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.23628v1.txt\n",
      "Downloading https://arxiv.org/html/2510.23178v1 \n",
      "\t Title: Feedback in Dynamic Contests: Theory and Experiment1footnote 11footnote 1The experiment was approved by the IRB at NYU Abu Dhabi and pre-registered with OSF. The pre-registration is available here. We gratefully acknowledge financial support from Tamkeen under the NYU Abu Dhabi Research Institute Award CG005.\n",
      "Wrote file ../data/raw/htmls/2510.23178v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.23178v1.txt\n",
      "Downloading https://arxiv.org/html/2510.22750v1 \n",
      "\t Title: Information-Credible Stability in Matching with Incomplete Information\n",
      "Wrote file ../data/raw/htmls/2510.22750v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.22750v1.txt\n",
      "Downloading https://arxiv.org/html/2510.22411v1 \n",
      "\t Title: Politics, Inequality, and the Robustness of Shared Infrastructure Systems\n",
      "Wrote file ../data/raw/htmls/2510.22411v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.22411v1.txt\n",
      "Downloading https://arxiv.org/html/2510.22086v1 \n",
      "\t Title: Social preferences or moral concerns: What drives rejections in the Ultimatum game?We are grateful to Ingela Alger, Ernesto María Gavassa-Pérez, Emin Karagözoğlu, Enrico Mattia-Salonia, Esteban Muñoz-Sobrado and Juan Sebastián Pereyra for their valuable discussions. We thank Pablo Brañas-Garza and Antonio Espín for kindly sharing their data with us. Pau Juan-Bartroli acknowledges funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement No 789111 - ERC EvolvingEconomics).\n",
      "Wrote file ../data/raw/htmls/2510.22086v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.22086v1.txt\n",
      "Downloading https://arxiv.org/html/2510.21759v1 \n",
      "\t Title: Entry Deterrence with Partial Reputation Spillovers1footnote 11footnote 1We thank Emiliano Catonini, Alla Friedman, Markus Gebauer, Vitalijs Jascisens, Ella Khromova, Steven Kivinen, Ekaterina Mitskevich, Konstantinos Shamruk, and Alexey Verenikin for helpful comments and conversations. All remaining errors are our own.\n",
      "Wrote file ../data/raw/htmls/2510.21759v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.21759v1.txt\n",
      "Downloading https://arxiv.org/html/2510.22828v1 \n",
      "\t Title: Efficiently Learning Synthetic Control Models for High-dimensional Disaggregated Data\n",
      "Wrote file ../data/raw/htmls/2510.22828v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.22828v1.txt\n",
      "Downloading https://arxiv.org/html/2510.22232v1 \n",
      "\t Title: Rational Adversaries and the Maintenance of Fragility: A Game-Theoretic Theory of Rational Stagnation\n",
      "Wrote file ../data/raw/htmls/2510.22232v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.22232v1.txt\n",
      "Downloading https://arxiv.org/html/2510.19630v2 \n",
      "\t Title: Network Contagion Dynamics in European Banking: A Navier-Stokes Framework for Systemic Risk Assessment\n",
      "Wrote file ../data/raw/htmls/2510.19630v2.txt\n",
      "Wrote file ../data/raw/abstracts/2510.19630v2.txt\n",
      "Downloading https://arxiv.org/html/2510.15324v3 \n",
      "\t Title: Dynamic Spatial Treatment Effects as Continuous Functionals: Theory and Evidence from Healthcare Access\n",
      "Wrote file ../data/raw/htmls/2510.15324v3.txt\n",
      "Wrote file ../data/raw/abstracts/2510.15324v3.txt\n",
      "Downloading https://arxiv.org/html/2510.14409v2 \n",
      "\t Title: Dynamic Spatial Treatment Effect Boundaries: A Continuous Functional Framework from Navier-Stokes Equations\n",
      "Wrote file ../data/raw/htmls/2510.14409v2.txt\n",
      "Wrote file ../data/raw/abstracts/2510.14409v2.txt\n",
      "Downloading https://arxiv.org/html/2510.13148v2 \n",
      "\t Title: Nonparametric Identification of Spatial Treatment Effect Boundaries: Evidence from Bank Branch Consolidation\n",
      "Wrote file ../data/raw/htmls/2510.13148v2.txt\n",
      "Wrote file ../data/raw/abstracts/2510.13148v2.txt\n",
      "Downloading https://arxiv.org/html/2510.12289v2 \n",
      "\t Title: Nonparametric Identification and Estimation of Spatial Treatment Effect Boundaries: Evidence from 42 Million Pollution Observations\n",
      "Wrote file ../data/raw/htmls/2510.12289v2.txt\n",
      "Wrote file ../data/raw/abstracts/2510.12289v2.txt\n",
      "Downloading https://arxiv.org/html/2510.20986v1 \n",
      "\t Title: Constrained Mediation: Bayesian Implementability of Joint PosteriorsLagziel acknowledges the support of the Israel Science Foundation, Grant #2074/23. Lehrer acknowledges the support of the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) – Project Number 461570745.\n",
      "Wrote file ../data/raw/htmls/2510.20986v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.20986v1.txt\n",
      "Downloading https://arxiv.org/html/2510.20921v1 \n",
      "\t Title: Discrete ScreeningWe thank Pierpaolo Battigalli for comments on our companion paper “Rationalizable screening and disclosure under unawareness” that lead to the development of the current paper. Burkhard gratefully acknowledges financial support through ARO Contract W911NF2210282.\n",
      "Wrote file ../data/raw/htmls/2510.20921v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.20921v1.txt\n",
      "Downloading https://arxiv.org/html/2510.20918v1 \n",
      "\t Title: Rationalizable Screening and Disclosure under UnawarenessWe thank Pierpaolo Battigalli, Kym Pram, the AE, and two anonymous reviewers for detailed comments on an earlier draft. Moreover, we thank Antonio Penta and participants in seminars at UC Davis, UW Bothell, UW Seattle, UW Tacoma, Monash University, Universidad Torcuato Di Tella, and Stony Brook University as well as the Conference on “Unawareness and Unintended Consequences,” 2021, the Zoom Mini-Workshop on “Contract theory with unawareness,” 2021, the Canadian Economic Association Conference, 2021, and SAET 2023. Burkhard gratefully acknowledges financial support through ARO Contract W911NF2210282.\n",
      "Wrote file ../data/raw/htmls/2510.20918v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.20918v1.txt\n",
      "Downloading https://arxiv.org/html/2510.20907v1 \n",
      "\t Title: The Economics of Convex Function IntervalsWe are indebted to Andreas Kleiner for numerous insightful discussions and comments. We are also particularly grateful to Sarah Auster and Eduardo Perez-Richet for their guidance and support. We would also like to thank Thomas Brzustowski, Gregorio Curello, Francesc Dilmé, Piotr Dworczak, Pia Ennuschat, Atulya Jain, Stephan Lauermann, Qianjun Lyu, Franz Ostrizek, Philipp Strack and Yimeng Zhang for helpful feedback at various stages of the project. We also thank audiences at Bonn, Mannheim, the CRC TR 224 EPoS Young Researchers Workshop, the 2025 IMD Days in Warsaw, the 2025 SAET conference in Ischia, and the 8th Lindau Nobel Meeting in Economic Sciences. Support by the German Research Foundation (DFG) through CRC TR 224 EPoS (Projects B01 (Augias) and B03 (Uhe)) is gratefully acknowledged. All remaining errors are ours.\n",
      "Wrote file ../data/raw/htmls/2510.20907v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.20907v1.txt\n",
      "Downloading https://arxiv.org/html/2510.21397v1 \n",
      "\t Title: Optimal Policies for Environmental Assets under Spatial Heterogeneity and Global Awareness\n",
      "Wrote file ../data/raw/htmls/2510.21397v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.21397v1.txt\n",
      "Downloading https://arxiv.org/html/2510.21231v1 \n",
      "\t Title: Scale-robust AuctionsWork done in part while all authors are supported by NSF CCF 1618502. An extended abstract of this work has appeared in 61st Annual Symposium on Foundations of Computer Science (FOCS’20) under the title “Benchmark Design and Prior-independent Optimization”. The authors thank Tan Gan, Shengwu Li, Eran Shmaya and Philipp Strack for helpful comments and suggestions.\n",
      "Wrote file ../data/raw/htmls/2510.21231v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.21231v1.txt\n",
      "Downloading https://arxiv.org/html/2510.20631v1 \n",
      "\t Title: Bilevel Programming Problems: A view through Set-valued Optimization\n",
      "Wrote file ../data/raw/htmls/2510.20631v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.20631v1.txt\n",
      "Downloading https://arxiv.org/html/2510.20606v1 \n",
      "\t Title: Strategic Costs of Perceived Bias in Fair Selection\n",
      "Wrote file ../data/raw/htmls/2510.20606v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.20606v1.txt\n",
      "Downloading https://arxiv.org/html/2510.19204v1 \n",
      "\t Title: Stability and slow dynamics of an interior spiky pattern in a one-dimensional spatial Solow model with capital-induced labor migration\n",
      "Wrote file ../data/raw/htmls/2510.19204v1.txt\n",
      "Wrote file ../data/raw/abstracts/2510.19204v1.txt\n"
     ]
    }
   ],
   "source": [
    "paper_contents = []\n",
    "\n",
    "for url in paper_urls:\n",
    "    paper_html_content = rq.get(url, headers = headers).text\n",
    "\n",
    "    if len(paper_html_content) > 3000:\n",
    "        html_id = url.split(\"/\")[-1]\n",
    "        print(url)\n",
    "        \n",
    "        # Check if we already downloaded both files, otherwise skip it to reduce processing time.\n",
    "        full_content_file = f\"{data_path}/raw/htmls/{html_id}.txt\"\n",
    "        abstract_content_file = f\"{data_path}/raw/abstracts/{html_id}.txt\"\n",
    "        parsed_sections_file = f\"{data_path}/raw/parsed_sections/{html_id}.json\"\n",
    "        full_file_already_exists = check_file_exists(path=full_content_file)\n",
    "        abs_file_already_exists = check_file_exists(path=abstract_content_file)\n",
    "\n",
    "        if full_file_already_exists and abs_file_already_exists:\n",
    "            print(f\"Both files for {html_id} already downloaded, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Get content of paper url\n",
    "        paper_soup = BeautifulSoup(paper_html_content, \"html.parser\")\n",
    "        title = get_title(soup=paper_soup)\n",
    "\n",
    "        # Obtain the abstract from the paper content\n",
    "        try:\n",
    "            abstract = get_abstract(paper_soup)\n",
    "        except AttributeError as e:\n",
    "            print(f\"\\033[93m Skipping {html_id} as it does not have an abstract. \\033[0m\")\n",
    "            continue\n",
    "        try:\n",
    "            sections = get_sections(paper_soup.find(\"html\",recursive=False).find(\"body\", recursive=False).find(\"div\",class_=\"ltx_page_main\", recursive=False).find(\"div\",class_=\"ltx_page_content\", recursive=False).find(\"article\", recursive=False))\n",
    "        except Exception as e:\n",
    "            print(f\"\\033[93m Error parsing html sections \\033[0m\")\n",
    "            continue\n",
    "        # Write files\n",
    "        print(f\"Downloading {url} \\n\\t Title: {title}\")\n",
    "        with open(full_content_file, \"w\", encoding=\"utf8\") as f:\n",
    "            f.writelines(paper_html_content)\n",
    "            print(f\"Wrote file {full_content_file}\")\n",
    "        with open(abstract_content_file, \"w\", encoding=\"utf8\") as f:\n",
    "            f.writelines(abstract)\n",
    "            print(f\"Wrote file {abstract_content_file}\")\n",
    "        with open(parsed_sections_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(sections, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print(f\"\\033[93m Skipping {url}, not enough characters in HTML content. \\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb1c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a4350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
